{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808d9ee2-a4a9-45db-b0fb-0fe5baa0c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"./llms_for_legal\")\n",
    "sys.path.append(\"./llms_for_legal/modules/pygaggle\")\n",
    "os.environ[\"JVM_PATH\"] = \"/home/s2210405/jdk-19.0.2/lib/server/libjvm.so\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f5b34",
   "metadata": {},
   "source": [
    "## Predict cases with monot5-large-10k hard-negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f24244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 11:55:29.808035: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-16 11:55:29.855315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 11:55:31.072714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from eval_monot5 import predict_all_monot5, predict_all_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652ea642-68e0-4a7d-a27d-4600fe633667",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_scores = predict_all_bm25(\n",
    "    dataset_path=\"./data/task2_train_files_2024\",\n",
    "    bm25_index_path=\"./data/bm25_indexes/coliee_task2/test\",\n",
    "    eval_segment=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74c17b3-6982-4e1a-8e33-730342e5cf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "monot5_scores = predict_all_monot5(\n",
    "    ckpt_path=\"./llms_for_legal/train_logs/monot5-large-10k_ns/ckpt\",\n",
    "    dataset_path=\"./data/task2_train_files_2024\",\n",
    "    eval_segment=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d569f1-dfb7-4164-9592-763abaf4c689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 13:45:43 [INFO] env: \n",
      "Using override env var JVM_PATH (/home/s2210405/jdk-19.0.2/lib/server/libjvm.so) to load libjvm.\n",
      "Please report your system information (os version, java\n",
      "version, etc), and the path that works for you, to the\n",
      "PyJNIus project, at https://github.com/kivy/pyjnius/issues.\n",
      "so we can improve the automatic discovery.\n",
      "\n",
      "2024-01-16 13:45:44 [INFO] loader: Loading faiss with AVX2 support.\n",
      "2024-01-16 13:45:44 [INFO] loader: Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "2024-01-16 13:45:44 [INFO] loader: Loading faiss.\n",
      "2024-01-16 13:45:44 [INFO] loader: Successfully loaded faiss.\n",
      "2024-01-16 13:45:45.948476: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-16 13:45:45.950513: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-16 13:45:45.996026: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 13:45:47.218067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from llms_for_legal.src.data import get_task2_data\n",
    "import os\n",
    "\n",
    "corpus_dir, cases_dir, label_data = get_task2_data(\n",
    "    dataset_path=\"./data/task2_train_files_2024\",\n",
    "    segment=\"val\"\n",
    ")\n",
    "\n",
    "\n",
    "def get_pred_cases(scores, bm25_scores, top_k, margin, alpha):\n",
    "    pred_cases = {}\n",
    "    for case in cases_dir:\n",
    "        bm25_score = bm25_scores[case]\n",
    "        score = scores[case]\n",
    "\n",
    "        candidate_dir = corpus_dir / case / \"paragraphs\"\n",
    "        candidate_cases = sorted(os.listdir(candidate_dir))\n",
    "\n",
    "        final_score = []\n",
    "        for cand_case in candidate_cases:\n",
    "            if alpha == 1:\n",
    "                if cand_case not in bm25_score:\n",
    "                    final_score.append(0)\n",
    "                else:\n",
    "                    final_score.append(score[cand_case])\n",
    "            else:\n",
    "                final_score.append(\n",
    "                    [\n",
    "                        cand_case,\n",
    "                        alpha * score[cand_case]\n",
    "                        + (1 - alpha) * bm25_score.get(cand_case, 0),\n",
    "                    ]\n",
    "                )\n",
    "        final_score = list(sorted(final_score, key=lambda x: -x[1]))\n",
    "\n",
    "        top_ind = final_score[:top_k]\n",
    "        pred_ind = [top_ind[0]]\n",
    "        for cand in top_ind[1:]:\n",
    "            if top_ind[0][1] - cand[1] < margin:\n",
    "                pred_ind.append([cand[0], cand[1]])\n",
    "\n",
    "        pred_cases[case] = pred_ind\n",
    "        pred_cases[case] = top_ind\n",
    "\n",
    "    return pred_cases\n",
    "    \n",
    "monot5_pred_cases = get_pred_cases(\n",
    "    scores=monot5_scores, bm25_scores=bm25_scores, top_k=1, margin=0, alpha=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64111375",
   "metadata": {},
   "source": [
    "## Few-shot Learning with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986f2ae8-d499-462c-9947-b23cc50a1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bm25_scores = json.load(open(\"./data/bm25_scores.json\"))\n",
    "monot5_scores = json.load(open(\"./data/monot5_scores.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a836b45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71532e9e878e4baea5c54a198be36eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_checkpoint = \"google/flan-t5-xxl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_checkpoint, torch_dtype=torch.float16, load_in_8bit=True, device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0635f01-18b5-4287-ba71-b84503991b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def load_txt(file_path, skip=0):\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        while skip > 0:\n",
    "            f.readline()\n",
    "            skip -= 1\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_case_data(\n",
    "    file_path,\n",
    "    max_length=None,\n",
    "    min_sentence_length=None,\n",
    "    uncased=False,\n",
    "    filter_min_length=None,\n",
    "):\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    text = load_txt(file_path)\n",
    "\n",
    "    text = (\n",
    "        text.strip()\n",
    "        .replace(\"\\n\", \" \")\n",
    "        .replace(\"FRAGMENT_SUPPRESSED\", \"\")\n",
    "        .replace(\"FACTUAL\", \"\")\n",
    "        .replace(\"BACKGROUND\", \"\")\n",
    "        .replace(\"ORDER\", \"\")\n",
    "    )\n",
    "    if uncased:\n",
    "        text = text.lower()\n",
    "    text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "    text = \" \".join([w for w in text.split() if w])\n",
    "\n",
    "    cite_number = re.search(\"\\[[0-9]+\\]\", text)\n",
    "    if cite_number:\n",
    "        text = text[cite_number.span()[1] :].strip()\n",
    "    if filter_min_length:\n",
    "        words = text.split()\n",
    "        if len(words) <= filter_min_length:\n",
    "            return None\n",
    "\n",
    "    if min_sentence_length:\n",
    "        text = filter_document(text, min_sentence_length)\n",
    "    if max_length:\n",
    "        words = text.split()[:max_length]\n",
    "        text = \" \".join(words)\n",
    "    if not text.endswith(\".\"):\n",
    "        text = text + \".\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def format_output(text):\n",
    "    CLEANR = re.compile(\"<.*?>\")\n",
    "    cleantext = re.sub(CLEANR, \"\", text)\n",
    "    return cleantext.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ac8b1",
   "metadata": {},
   "source": [
    "### Zero-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e3547f-70ab-4320-8fc2-1877355c497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "zero_shot_prompt_template = \"In bellow documents:\\n{}\\nQuestion: which documents really relevant to query '{}'?\"\n",
    "\n",
    "\n",
    "def zero_short_generate_prompt(query, candidates):\n",
    "    document_map = [\"\"] * len(candidates)\n",
    "    candidate_string_list = []\n",
    "    for i, cand in enumerate(candidates):\n",
    "        candidate_string_list.append(f\"Document {i+1}: {cand[1]}\")\n",
    "        document_map[i] = cand[0]\n",
    "    prompt = zero_shot_prompt_template.format(\n",
    "        \"\\n\".join(candidate_string_list), query\n",
    "    )\n",
    "    return prompt, document_map\n",
    "\n",
    "\n",
    "def get_document_id(answer, document_map):\n",
    "    return document_map[int(answer.split()[-1]) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acf8fb39-35b8-4116-b80e-1c7f8a295b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b8a166d58a40eebaf99e9b54acc55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_preds = {}\n",
    "for case, predictions in tqdm(monot5_pred_cases.items()):\n",
    "    if len(predictions) >= 2:\n",
    "        query = preprocess_case_data(\n",
    "            f\"./data/task2_train_files_2024/{case}/entailed_fragment.txt\"\n",
    "        )\n",
    "        candidates = [\n",
    "            (\n",
    "                pred[0],\n",
    "                preprocess_case_data(\n",
    "                    f\"./data/task2_train_files_2024/{case}/paragraphs/{pred[0]}\"\n",
    "                ),\n",
    "            )\n",
    "            for pred in predictions\n",
    "        ]\n",
    "        prompt, document_map = zero_short_generate_prompt(query, candidates)\n",
    "        with torch.no_grad():\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", padding=\"longest\").to(\"cuda\")[\n",
    "                \"input_ids\"\n",
    "            ]\n",
    "            outputs = model.generate(inputs, max_new_tokens=2)\n",
    "            raw_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            output_text = [format_output(e.replace(prompt, \"\")) for e in raw_output]\n",
    "            try:\n",
    "                final_preds[case] = [\n",
    "                    get_document_id(text, document_map) for text in output_text\n",
    "                ]\n",
    "            except:\n",
    "                print(raw_output)\n",
    "                print(case)\n",
    "                print(prompt)\n",
    "                break\n",
    "    else:\n",
    "        final_preds[case] = [predictions[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8283e56-c9cf-4ae3-b0d0-fd93594ce274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = monot5_pred_cases['526']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82b517f2-3ede-493d-8837-59f4cc309d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['024.txt', 92.46726432793902]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7c9c1",
   "metadata": {},
   "source": [
    "### Few-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beab8859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(file):\n",
    "    content = {}\n",
    "    with open(file) as f:\n",
    "        content = json.load(f)\n",
    "    return content\n",
    "\n",
    "train_labels = load_json(\"./data/train_labels.json\")\n",
    "train_labels.update(load_json(\"./data/val_labels.json\"))\n",
    "test_labels = load_json(\"./data/test_labels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "349a88f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 86), (2, 9), (3, 4), (4, 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels_count = Counter([len(v) for _, v in test_labels.items()])\n",
    "labels_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05420f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_data = {}\n",
    "for case in Path(\"./data/task2_train_files_2024\").iterdir():\n",
    "    if int(case.name) <= 625:\n",
    "        entailed_fragment = preprocess_case_data(case / \"entailed_fragment.txt\")\n",
    "        candidates = []\n",
    "        for cand in Path(case / \"paragraphs\").iterdir():\n",
    "            cand_content = preprocess_case_data(cand)\n",
    "            candidates.append(\n",
    "                [\n",
    "                    cand.name,\n",
    "                    cand_content,\n",
    "                    1 if cand.name in train_labels[case.name] else 0,\n",
    "                ]\n",
    "            )\n",
    "        train_data[case.name] = {\n",
    "            \"fragment\": entailed_fragment,\n",
    "            \"candidates\": candidates,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef26c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shot_prompt_template = (\n",
    "    'In bellow documents:\\n{}\\nThe documents really relevant to query \"{}\" '\n",
    ")\n",
    "\n",
    "num_doc_per_shot = 5\n",
    "\n",
    "\n",
    "def shot_generate_prompt(query, candidates):\n",
    "    document_map = []\n",
    "    candidate_string_list = []\n",
    "    positive_candidates = [cand for cand in candidates if cand[2] == 1]\n",
    "    negative_candidates = [cand for cand in candidates if cand[2] == 0]\n",
    "    candidates = positive_candidates + random.sample(\n",
    "        negative_candidates,\n",
    "        min(len(negative_candidates), num_doc_per_shot - len(positive_candidates)),\n",
    "    )\n",
    "    random.shuffle(candidates)\n",
    "    for i, cand in enumerate(candidates):\n",
    "        document_map.append(cand[0])\n",
    "        candidate_string_list.append(f\"Document {i+1}: {cand[1]}\")\n",
    "\n",
    "    prompt = shot_prompt_template.format(\"\\n\".join(candidate_string_list), query)\n",
    "\n",
    "    answers = [document_map.index(cand[0]) for cand in positive_candidates]\n",
    "\n",
    "    if len(answers) == 1:\n",
    "        prompt += \"is \"\n",
    "    else:\n",
    "        prompt += \"are \"\n",
    "    prompt += \" \".join([f\"document {a+1}\" for a in answers]) + \".\"\n",
    "    return prompt, document_map\n",
    "\n",
    "\n",
    "num_shots = 3\n",
    "final_preds = {}\n",
    "\n",
    "for case, predictions in tqdm(monot5_pred_cases.items()):\n",
    "    query = preprocess_case_data(\n",
    "        f\"./data/task2_train_files_2024/{case}/entailed_fragment.txt\"\n",
    "    )\n",
    "    candidates = [\n",
    "        (\n",
    "            pred[0],\n",
    "            preprocess_case_data(\n",
    "                f\"./data/task2_train_files_2024/{case}/paragraphs/{pred[0]}\"\n",
    "            ),\n",
    "        )\n",
    "        for pred in predictions\n",
    "    ]\n",
    "    samples = random.sample(list(train_data.items()), num_shots)\n",
    "    few_shots = []\n",
    "    for case, sample in samples:\n",
    "        shot, document_map = shot_generate_prompt(\n",
    "            sample[\"fragment\"], sample[\"candidates\"]\n",
    "        )\n",
    "        few_shots.append(shot)\n",
    "    last_shot, document_map = zero_short_generate_prompt(query, candidates)\n",
    "    few_shots.append(last_shot)\n",
    "    prompt = \"\\n####\\n\".join(few_shots)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=\"longest\").to(\"cuda\")[\n",
    "            \"input_ids\"\n",
    "        ]\n",
    "        outputs = model.generate(inputs, max_new_tokens=2)\n",
    "        raw_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        output_text = [format_output(e.replace(prompt, \"\")) for e in raw_output]\n",
    "        final_preds[case] = [\n",
    "            get_document_id(text, document_map) for text in output_text\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976ee3c",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a27204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7614678899082568 0.83 0.7033898305084746\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "for case, pred in final_preds.items():\n",
    "    tp += len([p for p in pred if p in label_data[case]])\n",
    "p = tp / sum([len(v) for _, v in final_preds.items()])\n",
    "r = tp / sum([len(v) for _, v in label_data.items()])\n",
    "f = 2 * p * r / (p + r)\n",
    "print(f, p, r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
