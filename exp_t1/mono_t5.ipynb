{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import copy\n",
    "import random\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import TrainerCallback, AutoTokenizer\n",
    "os.chdir('/home/s2310409/workspace/coliee-2024/')\n",
    "from utils.misc import get_query, get_summary\n",
    "\n",
    "\n",
    "def load_data(dir):\n",
    "    with open(dir, 'r') as fp:\n",
    "        train_data = json.load(fp)\n",
    "\n",
    "    data = []\n",
    "    for key in train_data.keys():\n",
    "        data.append([key, train_data[key]])\n",
    "\n",
    "    return pd.DataFrame(data, columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query on all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # candidates: 50.0\n",
      "Precision: 0.03630094043887147\n",
      "Recall: 0.6967509025270758\n",
      "F1: 0.06900661462368154\n"
     ]
    }
   ],
   "source": [
    "with open('dataset/c2023/bm25_candidates_test.json', 'r') as fp:\n",
    "    candidate_dicts = json.load(fp)\n",
    "\n",
    "data_df = load_data(f'dataset/test.json')\n",
    "\n",
    "data_df['candidates'] = data_df['source'].apply(lambda x: candidate_dicts[x])\n",
    "data_df['query'] = data_df['source'].apply(lambda x: get_query(x))\n",
    "\n",
    "# calculate accuracy metrics for BM25 + TF-IDF\n",
    "correct = 0\n",
    "n_retrived = 0\n",
    "n_relevant = 0\n",
    "\n",
    "coverages = []\n",
    "\n",
    "for index, row in data_df.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    preds = row['candidates']\n",
    "    coverages.append(len(preds))\n",
    "    n_retrived += len(preds)\n",
    "    n_relevant += len(target)\n",
    "    for prediction in preds:\n",
    "        if prediction in target:\n",
    "            correct += 1\n",
    "\n",
    "precision = correct / n_retrived\n",
    "recall = correct / n_relevant\n",
    "\n",
    "print(f\"Average # candidates: {np.mean(coverages)}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {2 * precision * recall / (precision + recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>candidates</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>070318.txt</td>\n",
       "      <td>[015076.txt]</td>\n",
       "      <td>[032432.txt, 071237.txt, 019716.txt, 027423.tx...</td>\n",
       "      <td>rpo board adamidis guideline applicant hearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>077960.txt</td>\n",
       "      <td>[009054.txt, 040860.txt]</td>\n",
       "      <td>[071412.txt, 060516.txt, 024547.txt, 087722.tx...</td>\n",
       "      <td>removal custody child children order dunn idah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>042319.txt</td>\n",
       "      <td>[093691.txt, 075956.txt, 084953.txt, 022987.txt]</td>\n",
       "      <td>[027719.txt, 067612.txt, 059275.txt, 026904.tx...</td>\n",
       "      <td>beyer cross affidavit prothonotary examination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041766.txt</td>\n",
       "      <td>[039269.txt]</td>\n",
       "      <td>[071818.txt, 056351.txt, 009599.txt, 046346.tx...</td>\n",
       "      <td>drug clinical nds data 002 health omitted 08 n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>077407.txt</td>\n",
       "      <td>[038669.txt]</td>\n",
       "      <td>[038092.txt, 096647.txt, 056351.txt, 060210.tx...</td>\n",
       "      <td>communication 23 privilege litigation counsel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>085079.txt</td>\n",
       "      <td>[044669.txt, 003144.txt]</td>\n",
       "      <td>[080328.txt, 056351.txt, 068423.txt, 041404.tx...</td>\n",
       "      <td>cso promotions shephard cst adjudicator jse co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>031370.txt</td>\n",
       "      <td>[096341.txt, 060602.txt, 047107.txt, 084522.tx...</td>\n",
       "      <td>[027678.txt, 086122.txt, 060516.txt, 031040.tx...</td>\n",
       "      <td>removal peru irreparable applicant 3d spouse p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>085828.txt</td>\n",
       "      <td>[004301.txt, 074887.txt, 088994.txt]</td>\n",
       "      <td>[008459.txt, 053850.txt, 003821.txt, 087722.tx...</td>\n",
       "      <td>officer applicants india singh riots prra roop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>024957.txt</td>\n",
       "      <td>[015009.txt, 080348.txt]</td>\n",
       "      <td>[066045.txt, 077315.txt, 075868.txt, 022332.tx...</td>\n",
       "      <td>annuity seizure civil 224 unseizable debtor co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>060678.txt</td>\n",
       "      <td>[018625.txt]</td>\n",
       "      <td>[059067.txt, 029016.txt, 058608.txt, 019572.tx...</td>\n",
       "      <td>industrial jurisdiction infringement plaintiff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source                                             target  \\\n",
       "0    070318.txt                                       [015076.txt]   \n",
       "1    077960.txt                           [009054.txt, 040860.txt]   \n",
       "2    042319.txt   [093691.txt, 075956.txt, 084953.txt, 022987.txt]   \n",
       "3    041766.txt                                       [039269.txt]   \n",
       "4    077407.txt                                       [038669.txt]   \n",
       "..          ...                                                ...   \n",
       "314  085079.txt                           [044669.txt, 003144.txt]   \n",
       "315  031370.txt  [096341.txt, 060602.txt, 047107.txt, 084522.tx...   \n",
       "316  085828.txt               [004301.txt, 074887.txt, 088994.txt]   \n",
       "317  024957.txt                           [015009.txt, 080348.txt]   \n",
       "318  060678.txt                                       [018625.txt]   \n",
       "\n",
       "                                            candidates  \\\n",
       "0    [032432.txt, 071237.txt, 019716.txt, 027423.tx...   \n",
       "1    [071412.txt, 060516.txt, 024547.txt, 087722.tx...   \n",
       "2    [027719.txt, 067612.txt, 059275.txt, 026904.tx...   \n",
       "3    [071818.txt, 056351.txt, 009599.txt, 046346.tx...   \n",
       "4    [038092.txt, 096647.txt, 056351.txt, 060210.tx...   \n",
       "..                                                 ...   \n",
       "314  [080328.txt, 056351.txt, 068423.txt, 041404.tx...   \n",
       "315  [027678.txt, 086122.txt, 060516.txt, 031040.tx...   \n",
       "316  [008459.txt, 053850.txt, 003821.txt, 087722.tx...   \n",
       "317  [066045.txt, 077315.txt, 075868.txt, 022332.tx...   \n",
       "318  [059067.txt, 029016.txt, 058608.txt, 019572.tx...   \n",
       "\n",
       "                                                 query  \n",
       "0    rpo board adamidis guideline applicant hearing...  \n",
       "1    removal custody child children order dunn idah...  \n",
       "2    beyer cross affidavit prothonotary examination...  \n",
       "3    drug clinical nds data 002 health omitted 08 n...  \n",
       "4    communication 23 privilege litigation counsel ...  \n",
       "..                                                 ...  \n",
       "314  cso promotions shephard cst adjudicator jse co...  \n",
       "315  removal peru irreparable applicant 3d spouse p...  \n",
       "316  officer applicants india singh riots prra roop...  \n",
       "317  annuity seizure civil 224 unseizable debtor co...  \n",
       "318  industrial jurisdiction infringement plaintiff...  \n",
       "\n",
       "[319 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mono T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(document, query):\n",
    "    return f'##Query: {query} ##Document: {document} ##Relevant:'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    TrainingArguments\n",
    ")\n",
    "ckpt_dir = os.path.join('./train_logs/monot5-large-10k_hns/ckpt/checkpoint-521')\n",
    "tokenizer = AutoTokenizer.from_pretrained('castorini/monot5-large-msmarco-10k')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(ckpt_dir).to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Query: rpo board guideline adamidis applicant france hearing bias ldk actions refugee apprehension member protection immigration recuse port kosovo cvv officer negative findings inference members mosley ##Document: Pelletier, J. : This is an application under section 82.1 of the Immigration Act, R.S.C. 1985, c. The CRDD found that the applicant was not a credible witness. The applicant argues that the CRDD's finding of implausibility was unreasonable. Application for judicial review of the decision of the Convention Refugee Determination Division, dated December 16, 1999. The application for judicial review of ten applicants were heard together because of certain common issues, one of which was whether the applicants had become refugee sur place. Each of the applicants made a claim before the Convention Refugee Determination Division (\"CRDD\") on the basis of well-founded fear of persecution of imputed political opinion The CRDD found that there was insufficient objective grounds to fear harassment by snakeheads upon return to China. The CRDD found that the claimant had not met his burden to demonstrate that the intent or principal effect on him of the Chinese law concerning illegal exit would be persecutory in relation to a Convention ground. [see footnote 11] Counsel for the applicants submitted that it was irrelevant whether the applicants could or could not be identified from the videos submitted in evidence and whether China would or would not know about the present claim for refugee status. Mr. Markaki argued that this question should have been addressed, even in the absence of specific documentary evidence, but on its knowledge of country conditions and the general documentary evidence which describes China as an oppressive regime which does not tolerate any political opposition or criticism of any kind. I agree with Mr. Markaki that the CRDD should have determined how the Chinese government might view making a claim for refugee status \"even in the absence of specific documentary evidence\". I find that the CRDD did not commit a reviewable error in its evaluation of the applicants' sur place claim. [1999] F.C.J. No. 525 (T.D.) (QL) ##Relevant:\n"
     ]
    }
   ],
   "source": [
    "e_id = 0\n",
    "source = data_df.iloc[e_id].source\n",
    "candidates = data_df.iloc[e_id].candidates\n",
    "query = data_df.iloc[e_id].query\n",
    "for candidate in candidates:\n",
    "    candidate_summary = get_summary('015076.txt')\n",
    "    text = prompt(document=tokenizer.decode(tokenizer.encode(candidate_summary, add_special_tokens=False, max_length=450, truncation=True)), query=query)\n",
    "    print(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedySearchEncoderDecoderOutput(sequences=tensor([[   0, 1176,    1]], device='cuda:0'), scores=(tensor([[-31.0093, -17.6671, -17.9352,  ..., -46.2695, -46.2710, -46.3849]],\n",
       "       device='cuda:0'), tensor([[-127.4821,  -40.6877,  -88.1471,  ..., -174.7162, -175.4172,\n",
       "         -175.3853]], device='cuda:0')), encoder_attentions=None, encoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, decoder_hidden_states=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt').to('cuda')\n",
    "outputs = model.generate(**inputs, output_scores=True, return_dict_in_generate=True, max_new_tokens=10)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> false</s>'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 6136,    1], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-33.8814, -18.8008, -19.5146,  ..., -48.9525, -48.9488, -49.0627]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-128.0669,  -41.3602,  -88.5412,  ..., -175.1797, -175.8803,\n",
       "          -175.8492]], device='cuda:0'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(outputs.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/319 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 319/319 [54:18<00:00, 10.21s/it]\n"
     ]
    }
   ],
   "source": [
    "prediction_dict = {}\n",
    "for e_id in tqdm(range(len(data_df))):\n",
    "    source = data_df.iloc[e_id].source\n",
    "    candidates = data_df.iloc[e_id].candidates\n",
    "    query = data_df.iloc[e_id].query\n",
    "    prediction_dict[source] = {\n",
    "        'result':[],\n",
    "        'raw':{}\n",
    "    }\n",
    "    for candidate in candidates:\n",
    "        candidate_summary = summary_data[candidate]\n",
    "        text = prompt(document=tokenizer.decode(tokenizer.encode(candidate_summary, add_special_tokens=False, max_length=450, truncation=True)), query=query)\n",
    "        inputs = tokenizer(text, return_tensors='pt').to('cuda')\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, output_scores=True, return_dict_in_generate=True, max_new_tokens=10)\n",
    "            prediction_dict[source]['raw'] = {\n",
    "                'sequences': list(outputs.sequences[0].cpu().detach().numpy()),\n",
    "                'scores': list([outputs.scores[0].cpu().detach().numpy(), outputs.scores[1].cpu().detach().numpy()])\n",
    "            }\n",
    "            decoded_output = tokenizer.decode(outputs.sequences[0])\n",
    "            if 'true' in decoded_output:\n",
    "                prediction_dict[source]['result'].append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.08880463032844525\n",
      "Precision: 0.016011138183083886\n",
      "Recall: 0.6642599277978339\n",
      "F1: 0.0312685869657575\n"
     ]
    }
   ],
   "source": [
    "data_df['prediction'] = data_df['source'].apply(lambda x: prediction_dict[x]['result'])\n",
    "\n",
    "# calculate accuracy metrics for BM25 + TF-IDF\n",
    "correct = 0\n",
    "n_retrived = 0\n",
    "n_relevant = 0\n",
    "\n",
    "coverages = []\n",
    "\n",
    "for index, row in data_df.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    preds = row['prediction']\n",
    "    coverages.append(len(preds))\n",
    "    n_retrived += len(preds)\n",
    "    n_relevant += len(target)\n",
    "    for prediction in preds:\n",
    "        if prediction in target:\n",
    "            correct += 1\n",
    "\n",
    "precision = correct / n_retrived\n",
    "recall = correct / n_relevant\n",
    "\n",
    "print(f\"Coverage: {np.mean(coverages)/len(file_list)}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {2 * precision * recall / (precision + recall)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pygaggle reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 16:43:23 [INFO] env: \n",
      "Using override env var JVM_PATH (/home/s2310409/jdk/lib/server/libjvm.so) to load libjvm.\n",
      "Please report your system information (os version, java\n",
      "version, etc), and the path that works for you, to the\n",
      "PyJNIus project, at https://github.com/kivy/pyjnius/issues.\n",
      "so we can improve the automatic discovery.\n",
      "\n",
      "2024-01-12 16:43:24 [INFO] loader: Loading faiss with AVX2 support.\n",
      "2024-01-12 16:43:24 [INFO] loader: Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/s2310409/workspace/coliee-2024/modules/pygaggle')\n",
    "from utils.dataset import build_dataset\n",
    "\n",
    "test_dataset = build_dataset(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 505/505 [00:01<00:00, 406.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2024-01-13 14:01:32,202 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Setting log level to INFO\n",
      "2024-01-13 14:01:32,203 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Starting indexer...\n",
      "2024-01-13 14:01:32,203 INFO  [main] index.IndexCollection (IndexCollection.java:395) - ============ Loading Parameters ============\n",
      "2024-01-13 14:01:32,203 INFO  [main] index.IndexCollection (IndexCollection.java:396) - DocumentCollection path: tmp\n",
      "2024-01-13 14:01:32,203 INFO  [main] index.IndexCollection (IndexCollection.java:397) - CollectionClass: JsonCollection\n",
      "2024-01-13 14:01:32,203 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Generator: DefaultLuceneDocumentGenerator\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Threads: 1\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Language: en\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Stemmer: porter\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:402) - Keep stopwords? false\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:403) - Stopwords: null\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:404) - Store positions? true\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:405) - Store docvectors? true\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:406) - Store document \"contents\" field? false\n",
      "2024-01-13 14:01:32,204 INFO  [main] index.IndexCollection (IndexCollection.java:407) - Store document \"raw\" field? true\n",
      "2024-01-13 14:01:32,205 INFO  [main] index.IndexCollection (IndexCollection.java:408) - Additional fields to index: []\n",
      "2024-01-13 14:01:32,205 INFO  [main] index.IndexCollection (IndexCollection.java:409) - Optimize (merge segments)? false\n",
      "2024-01-13 14:01:32,205 INFO  [main] index.IndexCollection (IndexCollection.java:410) - Whitelist: null\n",
      "2024-01-13 14:01:32,205 INFO  [main] index.IndexCollection (IndexCollection.java:411) - Pretokenized?: false\n",
      "2024-01-13 14:01:32,205 INFO  [main] index.IndexCollection (IndexCollection.java:412) - Index path: bm25/dev\n",
      "2024-01-13 14:01:32,206 INFO  [main] index.IndexCollection (IndexCollection.java:450) - ============ Indexing Collection ============\n",
      "2024-01-13 14:01:32,449 INFO  [main] index.IndexCollection (IndexCollection.java:565) - Thread pool with 1 threads initialized.\n",
      "2024-01-13 14:01:32,449 INFO  [main] index.IndexCollection (IndexCollection.java:567) - Initializing collection in tmp\n",
      "2024-01-13 14:01:32,451 INFO  [main] index.IndexCollection (IndexCollection.java:576) - 1 file found\n",
      "2024-01-13 14:01:32,451 INFO  [main] index.IndexCollection (IndexCollection.java:577) - Starting to index...\n",
      "2024-01-13 14:01:34,095 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - tmp/candidate.jsonl: 505 docs added.\n",
      "2024-01-13 14:01:34,452 INFO  [main] index.IndexCollection (IndexCollection.java:633) - Indexing Complete! 505 documents indexed\n",
      "2024-01-13 14:01:34,452 INFO  [main] index.IndexCollection (IndexCollection.java:634) - ============ Final Counter Values ============\n",
      "2024-01-13 14:01:34,453 INFO  [main] index.IndexCollection (IndexCollection.java:635) - indexed:              505\n",
      "2024-01-13 14:01:34,453 INFO  [main] index.IndexCollection (IndexCollection.java:636) - unindexable:            0\n",
      "2024-01-13 14:01:34,453 INFO  [main] index.IndexCollection (IndexCollection.java:637) - empty:                  0\n",
      "2024-01-13 14:01:34,453 INFO  [main] index.IndexCollection (IndexCollection.java:638) - skipped:                0\n",
      "2024-01-13 14:01:34,453 INFO  [main] index.IndexCollection (IndexCollection.java:639) - errors:                 0\n",
      "2024-01-13 14:01:34,460 INFO  [main] index.IndexCollection (IndexCollection.java:642) - Total 505 documents indexed in 00:00:02\n",
      "pyserini.index is deprecated, please use pyserini.index.lucene.\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "\n",
    "def create_bm25_indexes(segment=\"test\"):\n",
    "    tmp_dir = \"tmp\"\n",
    "    shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "    \n",
    "    indexes_dir = f'bm25/{segment}'\n",
    "    shutil.rmtree(indexes_dir, ignore_errors=True)\n",
    "    os.makedirs(indexes_dir, exist_ok=True)\n",
    "\n",
    "    with open(f'dataset/{segment}.json', 'r') as fp:\n",
    "        data_dict = json.load(fp)\n",
    "    \n",
    "    all_files = []\n",
    "    for key in data_dict.keys():\n",
    "        all_files.append(key)\n",
    "        all_files.extend(data_dict[key])\n",
    "    file_list = list(set(all_files))\n",
    "\n",
    "    if segment == \"test\":\n",
    "        file_list = [f for f in os.listdir(f'dataset/c2023/{segment}_files') if f.endswith('.txt')]\n",
    "    file_list = sorted(file_list)\n",
    "\n",
    "    processed_file_dict = {}\n",
    "    for file in [f for f in os.listdir(\"dataset/processed\") if not f.startswith('.')]:\n",
    "        processed_file = f\"dataset/processed/{file}\"\n",
    "        with open(processed_file, 'r') as fp:\n",
    "            processed_document = fp.read()\n",
    "            processed_file_dict[file] = {\n",
    "                'sentences': processed_document.split('\\n\\n'),\n",
    "                'processed_document': processed_document\n",
    "            }\n",
    "    \n",
    "    # data_df = build_df(mode=segment)\n",
    "    # for case in tqdm(data_df['source'].values):\n",
    "    #     base_case_num = case.split(\".txt\")[0]\n",
    "    #     candidate_cases = data_df[data_df['source'] == case]['candidates'].values[0]\n",
    "    #     for cand_case in candidate_cases:\n",
    "    #         cand_case_data = processed_file_dict[cand_case]['processed_document']\n",
    "    #         cand_num = cand_case.split(\".txt\")[0]\n",
    "    #         dict_ = { \"id\": f\"{base_case_num}_candidate{cand_num}.txt_task2\", \"contents\": cand_case_data}\n",
    "    #         with jsonlines.open(f\"{tmp_dir}/candidate.jsonl\", mode=\"a\") as writer:\n",
    "    #             writer.write(dict_)\n",
    "\n",
    "    for case in tqdm(file_list):\n",
    "        dict_  = { \"id\": f\"{case}\", \"contents\": processed_file_dict[case]['processed_document']}\n",
    "        with jsonlines.open(f\"{tmp_dir}/candidate.jsonl\", mode=\"a\") as writer:\n",
    "            writer.write(dict_)\n",
    "\n",
    "    subprocess.run([\"/home/s2310409/miniconda3/envs/coliee-24/bin/python\", \"-m\", \"pyserini.index\", \"-collection\", \"JsonCollection\",\n",
    "                    \"-generator\", \"DefaultLuceneDocumentGenerator\", \"-threads\", \"1\", \"-input\",\n",
    "                    f\"{tmp_dir}\", \"-index\", f\"{indexes_dir}\", \"-storePositions\", \"-storeDocvectors\",\n",
    "                    \"-storeRaw\"])\n",
    "    \n",
    "create_bm25_indexes(segment=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search import LuceneSearcher\n",
    "from collections import defaultdict\n",
    "\n",
    "def predict_bm25(searcher, query, case):\n",
    "    bm25_score = defaultdict(lambda: 0)\n",
    "    hits = searcher.search(query, k=10000)\n",
    "    for hit in hits:\n",
    "        if hit.docid != case:\n",
    "            bm25_score[hit.docid] = max(hit.score, bm25_score[hit.docid])\n",
    "    return bm25_score\n",
    "\n",
    "def predict_all_bm25(bm25_index_path, eval_segment=\"test\",\n",
    "                     k1=None, b=None, topk=None):\n",
    "    searcher = LuceneSearcher(bm25_index_path)\n",
    "    if k1 and b:\n",
    "        print(f\"k1: {k1}, b: {b}\")\n",
    "        searcher.set_bm25(k1, b)\n",
    "\n",
    "    with open(f'dataset/{eval_segment}.json', 'r') as fp:\n",
    "        data_dict = json.load(fp)\n",
    "\n",
    "    # file_list = [f for f in os.listdir(f'dataset/c2023/{eval_segment}_files') if f.endswith('.txt')]\n",
    "    file_list = list(data_dict.keys())\n",
    "    file_list = sorted(file_list)\n",
    "\n",
    "    bm25_scores = {}\n",
    "\n",
    "    for case in tqdm(file_list):\n",
    "        query = get_query(case)\n",
    "        try:\n",
    "            score = predict_bm25(searcher, query, case)\n",
    "        except:\n",
    "            print(f\"Error: {case}\")\n",
    "            raise Exception\n",
    "        if topk is not None:\n",
    "            sorted_score = sorted(score.items(), key=lambda x: x[1], reverse=True)[:topk]\n",
    "            score = {x[0]: x[1] for x in sorted_score}\n",
    "        bm25_scores[case] = score\n",
    "\n",
    "    # dataset_path = \"/home/thanhtc/mnt/datasets/COLIEE2023/Task2/data_org\"\n",
    "    # corpus_dir, cases_dir, _ = get_task2_data(dataset_path, eval_segment)\n",
    "    # bm25_scores = {}\n",
    "    # for case in cases_dir:\n",
    "    #     base_case_data = preprocess_case_data(corpus_dir / case / \"entailed_fragment.txt\")\n",
    "    #     score = predict_bm25(searcher, base_case_data, case)\n",
    "    #     if topk is not None:\n",
    "    #         sorted_score = sorted(score.items(), key=lambda x: x[1], reverse=True)[:topk]\n",
    "    #         score = {x[0]: x[1] for x in sorted_score}\n",
    "    #     bm25_scores[case] = score\n",
    "    return bm25_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygaggle.rerank.base import Query, Text\n",
    "from pygaggle.rerank.transformer import MonoT5\n",
    "from utils.misc import load_json\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, \\\n",
    "    T5ForConditionalGeneration\n",
    "\n",
    "def predict_monot5(reranker, doc, candidate_cases, config):\n",
    "    if config[\"train_uncased\"]:\n",
    "        doc = doc.lower()\n",
    "    query = Query(doc)\n",
    "    texts = []\n",
    "\n",
    "    for i, cand_case in enumerate(candidate_cases):\n",
    "        cand_case_data = get_summary(cand_case)\n",
    "        texts.append(Text(cand_case_data, metadata={\"docid\": cand_case}))\n",
    "\n",
    "    monot5_score = defaultdict(lambda: 0)\n",
    "    result = reranker.rerank(query, texts)\n",
    "    for c in result:\n",
    "        cand_id = c.metadata[\"docid\"]\n",
    "        monot5_score[cand_id] = max(\n",
    "            monot5_score[cand_id], np.exp(c.score) * 100)\n",
    "    return monot5_score\n",
    "\n",
    "def predict_all_monot5(ckpt_path, candidate_dict, eval_segment=\"test\"):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(ckpt_path).to(device).eval()\n",
    "    reranker = MonoT5(model=model)\n",
    "\n",
    "    if \"ckpt\" not in ckpt_path:\n",
    "        config = {\"train_uncased\": False}\n",
    "    else:\n",
    "        # root_dir = ckpt_path.split(\"ckpt\")[0]\n",
    "        # config_path = os.path.join(root_dir, \"train_configs.json\")\n",
    "        config_path = \"configs/monot5-large-10k_hns.json\"\n",
    "        config = load_json(config_path)\n",
    "\n",
    "    with open(f'dataset/{eval_segment}.json', 'r') as fp:\n",
    "        data_dict = json.load(fp)\n",
    "\n",
    "    # file_list = [f for f in os.listdir(f'dataset/c2023/{eval_segment}_files') if f.endswith('.txt')]\n",
    "    file_list = list(data_dict.keys())\n",
    "    file_list = sorted(file_list)\n",
    "\n",
    "    # with open('dataset/c2023/bm25_candidates_test.json', 'r') as fp:\n",
    "    #     candidate_dict = json.load(fp)\n",
    "\n",
    "    monot5_scores = {}\n",
    "    for case in tqdm(file_list):\n",
    "        query = get_query(case)\n",
    "        candidates = candidate_dict[case]\n",
    "        try:\n",
    "            score = predict_monot5(reranker, query, candidates, config)\n",
    "        except:\n",
    "            print(f\"Error: {case}\")\n",
    "            raise Exception\n",
    "        monot5_scores[case] = score\n",
    "\n",
    "    # corpus_dir, cases_dir, _ = get_task2_data(dataset_path, eval_segment)\n",
    "    # monot5_scores = {}\n",
    "    # for case in cases_dir:\n",
    "    #     base_case_data = preprocess_case_data(\n",
    "    #         corpus_dir / case / \"entailed_fragment.txt\", uncased=config[\"train_uncased\"])\n",
    "\n",
    "    #     candidate_dir = corpus_dir / case / \"paragraphs\"\n",
    "    #     score = predict_monot5(reranker, base_case_data, candidate_dir, config)\n",
    "    #     monot5_scores[case] = score\n",
    "    return monot5_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bm25_end_model_ranking(bm25_scores, scores, candidate_dict, top_k=1, margin=0, alpha=1,\n",
    "                                eval_segment=\"test\"):\n",
    "    print(f\"\\n[{eval_segment}] k: {top_k} - margin: {margin} - alpha: {alpha}\")\n",
    "\n",
    "    with open(f'dataset/{eval_segment}.json', 'r') as fp:\n",
    "        data_dict = json.load(fp)\n",
    "    \n",
    "    # file_list = [f for f in os.listdir(f'dataset/c2023/{eval_segment}_files') if f.endswith('.txt')]\n",
    "    file_list = list(data_dict.keys())\n",
    "    file_list = sorted(file_list)\n",
    "\n",
    "    # with open('dataset/c2023/bm25_candidates_test.json', 'r') as fp:\n",
    "    #     candidate_dict = json.load(fp)\n",
    "\n",
    "    with open(f'dataset/{eval_segment}.json', 'r') as fp:\n",
    "        label_data = json.load(fp)\n",
    "\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for case in label_data.keys():\n",
    "        bm25_score = bm25_scores[case]\n",
    "        score = scores[case]\n",
    "        candidate_cases = candidate_dict[case]\n",
    "        final_score = []\n",
    "        for cand_case in candidate_cases:\n",
    "            if alpha == 1:\n",
    "                if cand_case not in bm25_score:\n",
    "                    final_score.append(0)\n",
    "                else:\n",
    "                    final_score.append(score[cand_case])\n",
    "            else:\n",
    "                final_score.append(alpha * score[cand_case] + \n",
    "                                   (1 - alpha) * bm25_score.get(cand_case, 0))\n",
    "\n",
    "        label = [1 if f in label_data[case] else 0 for f in candidate_cases]\n",
    "        top_ind = np.argsort(final_score)[-top_k:]\n",
    "        pred_ind = [top_ind[-1]]\n",
    "        for i in top_ind[:-1]:\n",
    "            if final_score[top_ind[-1]] - final_score[i] < margin:\n",
    "                pred_ind.append(i)\n",
    "        pred = np.zeros_like(label)\n",
    "        pred[pred_ind] = 1\n",
    "\n",
    "        tp += np.sum([1 if a == b and a == 1 else 0 for a, b in zip(pred, label)])\n",
    "        fp += np.sum([1 if a != b and a == 1 else 0 for a, b in zip(pred, label)])\n",
    "        fn += np.sum([1 if a != b and a == 0 else 0 for a, b in zip(pred, label)])\n",
    "\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    f1 = 2 * ((p * r) / (p + r))\n",
    "\n",
    "    # print(f\"[{eval_segment}] Metrics: {[f1, p, r]} - {[top_k, margin, alpha]}\")\n",
    "    return [f1, p, r]\n",
    "\n",
    "def eval_bm25_end_model(bm25_index_path, candidate_dict, ckpt_path=None, top_k=None, margin=None, alpha=None,\n",
    "                        eval_segment=\"test\", model_class=\"monot5\"):\n",
    "    bm25_scores = predict_all_bm25(bm25_index_path, eval_segment)\n",
    "    if model_class == \"monot5\":\n",
    "        predict_func = predict_all_monot5\n",
    "    else:\n",
    "        raise ValueError(model_class)\n",
    "\n",
    "    scores = predict_func(ckpt_path, candidate_dict, eval_segment)\n",
    "    if top_k is None:\n",
    "        list_k = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        list_margin = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        list_alpha = [0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "        best_metric = [0, 0, 0]\n",
    "        best_config = []\n",
    "\n",
    "        for k in list_k:\n",
    "            for margin in list_margin:\n",
    "                for alpha in list_alpha:\n",
    "                    res = eval_bm25_end_model_ranking(bm25_scores, scores, candidate_dict, k, margin, alpha, eval_segment)\n",
    "                    if res[0] > best_metric[0]:\n",
    "                        best_metric = res\n",
    "                        best_config = [k, margin, alpha]\n",
    "        print(f\"[{eval_segment}] Best metrics: {best_metric} - {best_config}\")\n",
    "\n",
    "        if eval_segment == \"dev\":\n",
    "            bm25_test_index_path = \"bm25/test\"\n",
    "            bm25_test_scores = predict_all_bm25(bm25_test_index_path, eval_segment=\"test\")\n",
    "            with open('dataset/c2023/bm25_candidates_test_50.json', 'r') as fp:\n",
    "                test_candidate_dict = json.load(fp)\n",
    "\n",
    "            test_scores = predict_func(ckpt_path, test_candidate_dict, eval_segment=\"test\")\n",
    "            test_metric = eval_bm25_end_model_ranking(bm25_test_scores, test_scores, test_candidate_dict,\n",
    "                best_config[0], best_config[1], best_config[2], \"test\")\n",
    "            print(f\"[test] Best metrics: {test_metric} - {best_config}\")\n",
    "            return best_metric, test_metric, best_config\n",
    "\n",
    "        return best_metric, best_config\n",
    "    else:\n",
    "        return eval_bm25_end_model_ranking(bm25_scores, scores, candidate_dict, top_k, margin, alpha, eval_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1335/1335 [03:47<00:00,  5.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1335/1335 [36:30<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "bm25_index_path='bm25/test'\n",
    "ckpt_path='train_logs/monot5-large-10k_hns/ckpt/checkpoint-521'\n",
    "top_k=2\n",
    "margin=2\n",
    "alpha=0.7\n",
    "eval_segment='test'\n",
    "model_class='monot5'\n",
    "\n",
    "bm25_scores = predict_all_bm25(bm25_index_path, eval_segment)\n",
    "scores = predict_all_monot5(ckpt_path, eval_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[test] k: 2 - margin: 2 - alpha: 0.7\n",
      "[test] Metrics: [0.19759450171821305, 0.19658119658119658, 0.19861830742659758] - [2, 2, 0.7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19759450171821305, 0.19658119658119658, 0.19861830742659758]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_bm25_end_model_ranking(bm25_scores, scores, top_k, margin, alpha, eval_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                         | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:06<00:00, 13.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:43<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[dev] k: 1 - margin: 0 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 0, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 0 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 0, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 0 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 0, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 0 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 0, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 0 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 0, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 0 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 0, 1]\n",
      "\n",
      "[dev] k: 1 - margin: 1 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 1, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 1 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 1, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 1 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 1, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 1 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 1, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 1 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 1, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 1 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 1, 1]\n",
      "\n",
      "[dev] k: 1 - margin: 2 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 2, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 2 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 2, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 2 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 2, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 2 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 2, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 2 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 2, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 2 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 2, 1]\n",
      "\n",
      "[dev] k: 1 - margin: 3 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 3, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 3 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 3, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 3 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 3, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 3 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 3, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 3 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 3, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 3 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 3, 1]\n",
      "\n",
      "[dev] k: 1 - margin: 4 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 4, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 4 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 4, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 4 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 4, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 4 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 4, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 4 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 4, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 4 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 4, 1]\n",
      "\n",
      "[dev] k: 1 - margin: 5 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 5, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 5 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 5, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 5 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 5, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 5 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 5, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 5 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 5, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 5 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 5, 1]\n",
      "\n",
      "[dev] k: 1 - margin: 6 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 6, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 6 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 6, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 6 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 6, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 6 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 6, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 6 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 6, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 6 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 6, 1]\n",
      "\n",
      "[dev] k: 1 - margin: 7 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 7, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 7 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 7, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 7 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 7, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 7 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 7, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 7 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 7, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 7 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 7, 1]\n",
      "\n",
      "[dev] k: 1 - margin: 8 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [1, 8, 0.5]\n",
      "\n",
      "[dev] k: 1 - margin: 8 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [1, 8, 0.6]\n",
      "\n",
      "[dev] k: 1 - margin: 8 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 8, 0.7]\n",
      "\n",
      "[dev] k: 1 - margin: 8 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 8, 0.8]\n",
      "\n",
      "[dev] k: 1 - margin: 8 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [1, 8, 0.9]\n",
      "\n",
      "[dev] k: 1 - margin: 8 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [1, 8, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 0 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [2, 0, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 0 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [2, 0, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 0 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [2, 0, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 0 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [2, 0, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 0 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [2, 0, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 0 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [2, 0, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 1 - alpha: 0.5\n",
      "[dev] Metrics: [0.2923728813559322, 0.5036496350364964, 0.20597014925373133] - [2, 1, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 1 - alpha: 0.6\n",
      "[dev] Metrics: [0.301255230125523, 0.5034965034965035, 0.21492537313432836] - [2, 1, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 1 - alpha: 0.7\n",
      "[dev] Metrics: [0.29979466119096504, 0.48026315789473684, 0.21791044776119403] - [2, 1, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 1 - alpha: 0.8\n",
      "[dev] Metrics: [0.3098591549295775, 0.47530864197530864, 0.2298507462686567] - [2, 1, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 1 - alpha: 0.9\n",
      "[dev] Metrics: [0.2868369351669941, 0.41954022988505746, 0.21791044776119403] - [2, 1, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 1 - alpha: 1\n",
      "[dev] Metrics: [0.21292775665399238, 0.2931937172774869, 0.16716417910447762] - [2, 1, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 2 - alpha: 0.5\n",
      "[dev] Metrics: [0.29918032786885246, 0.477124183006536, 0.21791044776119403] - [2, 2, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 2 - alpha: 0.6\n",
      "[dev] Metrics: [0.3132530120481928, 0.4785276073619632, 0.23283582089552238] - [2, 2, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 2 - alpha: 0.7\n",
      "[dev] Metrics: [0.32936507936507936, 0.4911242603550296, 0.24776119402985075] - [2, 2, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 2 - alpha: 0.8\n",
      "[dev] Metrics: [0.3100775193798449, 0.4419889502762431, 0.23880597014925373] - [2, 2, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 2 - alpha: 0.9\n",
      "[dev] Metrics: [0.29501915708812265, 0.4117647058823529, 0.2298507462686567] - [2, 2, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 2 - alpha: 1\n",
      "[dev] Metrics: [0.2125237191650854, 0.2916666666666667, 0.16716417910447762] - [2, 2, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 3 - alpha: 0.5\n",
      "[dev] Metrics: [0.3043478260869565, 0.4502923976608187, 0.2298507462686567] - [2, 3, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 3 - alpha: 0.6\n",
      "[dev] Metrics: [0.32421875, 0.4689265536723164, 0.24776119402985075] - [2, 3, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 3 - alpha: 0.7\n",
      "[dev] Metrics: [0.3255813953488372, 0.46408839779005523, 0.2507462686567164] - [2, 3, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 3 - alpha: 0.8\n",
      "[dev] Metrics: [0.3127413127413127, 0.4426229508196721, 0.2417910447761194] - [2, 3, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 3 - alpha: 0.9\n",
      "[dev] Metrics: [0.29333333333333333, 0.4052631578947368, 0.2298507462686567] - [2, 3, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 3 - alpha: 1\n",
      "[dev] Metrics: [0.2125237191650854, 0.2916666666666667, 0.16716417910447762] - [2, 3, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 4 - alpha: 0.5\n",
      "[dev] Metrics: [0.31189083820662766, 0.449438202247191, 0.23880597014925373] - [2, 4, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 4 - alpha: 0.6\n",
      "[dev] Metrics: [0.3217054263565891, 0.4585635359116022, 0.24776119402985075] - [2, 4, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 4 - alpha: 0.7\n",
      "[dev] Metrics: [0.32495164410058025, 0.46153846153846156, 0.2507462686567164] - [2, 4, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 4 - alpha: 0.8\n",
      "[dev] Metrics: [0.3109404990403071, 0.43548387096774194, 0.2417910447761194] - [2, 4, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 4 - alpha: 0.9\n",
      "[dev] Metrics: [0.2965779467680608, 0.4083769633507853, 0.23283582089552238] - [2, 4, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 4 - alpha: 1\n",
      "[dev] Metrics: [0.2125237191650854, 0.2916666666666667, 0.16716417910447762] - [2, 4, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 5 - alpha: 0.5\n",
      "[dev] Metrics: [0.313953488372093, 0.44751381215469616, 0.2417910447761194] - [2, 5, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 5 - alpha: 0.6\n",
      "[dev] Metrics: [0.321083172147002, 0.45604395604395603, 0.24776119402985075] - [2, 5, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 5 - alpha: 0.7\n",
      "[dev] Metrics: [0.3269230769230769, 0.4594594594594595, 0.2537313432835821] - [2, 5, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 5 - alpha: 0.8\n",
      "[dev] Metrics: [0.31297709923664124, 0.43386243386243384, 0.24477611940298508] - [2, 5, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 5 - alpha: 0.9\n",
      "[dev] Metrics: [0.29601518026565465, 0.40625, 0.23283582089552238] - [2, 5, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 5 - alpha: 1\n",
      "[dev] Metrics: [0.2125237191650854, 0.2916666666666667, 0.16716417910447762] - [2, 5, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 6 - alpha: 0.5\n",
      "[dev] Metrics: [0.313953488372093, 0.44751381215469616, 0.2417910447761194] - [2, 6, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 6 - alpha: 0.6\n",
      "[dev] Metrics: [0.3230769230769231, 0.4540540540540541, 0.2507462686567164] - [2, 6, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 6 - alpha: 0.7\n",
      "[dev] Metrics: [0.32629558541266795, 0.45698924731182794, 0.2537313432835821] - [2, 6, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 6 - alpha: 0.8\n",
      "[dev] Metrics: [0.3123809523809524, 0.43157894736842106, 0.24477611940298508] - [2, 6, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 6 - alpha: 0.9\n",
      "[dev] Metrics: [0.29601518026565465, 0.40625, 0.23283582089552238] - [2, 6, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 6 - alpha: 1\n",
      "[dev] Metrics: [0.2125237191650854, 0.2916666666666667, 0.16716417910447762] - [2, 6, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 7 - alpha: 0.5\n",
      "[dev] Metrics: [0.31538461538461543, 0.44324324324324327, 0.24477611940298508] - [2, 7, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 7 - alpha: 0.6\n",
      "[dev] Metrics: [0.3230769230769231, 0.4540540540540541, 0.2507462686567164] - [2, 7, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 7 - alpha: 0.7\n",
      "[dev] Metrics: [0.32887189292543023, 0.4574468085106383, 0.25671641791044775] - [2, 7, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 7 - alpha: 0.8\n",
      "[dev] Metrics: [0.3123809523809524, 0.43157894736842106, 0.24477611940298508] - [2, 7, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 7 - alpha: 0.9\n",
      "[dev] Metrics: [0.29601518026565465, 0.40625, 0.23283582089552238] - [2, 7, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 7 - alpha: 1\n",
      "[dev] Metrics: [0.2125237191650854, 0.2916666666666667, 0.16716417910447762] - [2, 7, 1]\n",
      "\n",
      "[dev] k: 2 - margin: 8 - alpha: 0.5\n",
      "[dev] Metrics: [0.31538461538461543, 0.44324324324324327, 0.24477611940298508] - [2, 8, 0.5]\n",
      "\n",
      "[dev] k: 2 - margin: 8 - alpha: 0.6\n",
      "[dev] Metrics: [0.3218390804597701, 0.44919786096256686, 0.2507462686567164] - [2, 8, 0.6]\n",
      "\n",
      "[dev] k: 2 - margin: 8 - alpha: 0.7\n",
      "[dev] Metrics: [0.3282442748091603, 0.455026455026455, 0.25671641791044775] - [2, 8, 0.7]\n",
      "\n",
      "[dev] k: 2 - margin: 8 - alpha: 0.8\n",
      "[dev] Metrics: [0.3123809523809524, 0.43157894736842106, 0.24477611940298508] - [2, 8, 0.8]\n",
      "\n",
      "[dev] k: 2 - margin: 8 - alpha: 0.9\n",
      "[dev] Metrics: [0.29601518026565465, 0.40625, 0.23283582089552238] - [2, 8, 0.9]\n",
      "\n",
      "[dev] k: 2 - margin: 8 - alpha: 1\n",
      "[dev] Metrics: [0.2125237191650854, 0.2916666666666667, 0.16716417910447762] - [2, 8, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 0 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [3, 0, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 0 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [3, 0, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 0 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [3, 0, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 0 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [3, 0, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 0 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [3, 0, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 0 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [3, 0, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 1 - alpha: 0.5\n",
      "[dev] Metrics: [0.30957230142566194, 0.48717948717948717, 0.22686567164179106] - [3, 1, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 1 - alpha: 0.6\n",
      "[dev] Metrics: [0.316, 0.47878787878787876, 0.23582089552238805] - [3, 1, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 1 - alpha: 0.7\n",
      "[dev] Metrics: [0.29902912621359223, 0.42777777777777776, 0.2298507462686567] - [3, 1, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 1 - alpha: 0.8\n",
      "[dev] Metrics: [0.32162661737523107, 0.4223300970873786, 0.25970149253731345] - [3, 1, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 1 - alpha: 0.9\n",
      "[dev] Metrics: [0.3143350604490501, 0.3729508196721312, 0.2716417910447761] - [3, 1, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 1 - alpha: 1\n",
      "[dev] Metrics: [0.2387096774193548, 0.2596491228070175, 0.2208955223880597] - [3, 1, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 2 - alpha: 0.5\n",
      "[dev] Metrics: [0.3193916349809886, 0.4397905759162304, 0.2507462686567164] - [3, 2, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 2 - alpha: 0.6\n",
      "[dev] Metrics: [0.33576642335766427, 0.431924882629108, 0.2746268656716418] - [3, 2, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 2 - alpha: 0.7\n",
      "[dev] Metrics: [0.34567901234567905, 0.4224137931034483, 0.29253731343283584] - [3, 2, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 2 - alpha: 0.8\n",
      "[dev] Metrics: [0.3288135593220339, 0.3803921568627451, 0.28955223880597014] - [3, 2, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 2 - alpha: 0.9\n",
      "[dev] Metrics: [0.31527093596059114, 0.35036496350364965, 0.2865671641791045] - [3, 2, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 2 - alpha: 1\n",
      "[dev] Metrics: [0.2379421221864952, 0.2578397212543554, 0.2208955223880597] - [3, 2, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 3 - alpha: 0.5\n",
      "[dev] Metrics: [0.3298245614035088, 0.4, 0.28059701492537314] - [3, 3, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 3 - alpha: 0.6\n",
      "[dev] Metrics: [0.3384615384615385, 0.396, 0.2955223880597015] - [3, 3, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 3 - alpha: 0.7\n",
      "[dev] Metrics: [0.346218487394958, 0.39615384615384613, 0.3074626865671642] - [3, 3, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 3 - alpha: 0.8\n",
      "[dev] Metrics: [0.3316749585406302, 0.373134328358209, 0.29850746268656714] - [3, 3, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 3 - alpha: 0.9\n",
      "[dev] Metrics: [0.31493506493506496, 0.34519572953736655, 0.28955223880597014] - [3, 3, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 3 - alpha: 1\n",
      "[dev] Metrics: [0.2375601926163724, 0.2569444444444444, 0.2208955223880597] - [3, 3, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 4 - alpha: 0.5\n",
      "[dev] Metrics: [0.33730834752981265, 0.39285714285714285, 0.2955223880597015] - [3, 4, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 4 - alpha: 0.6\n",
      "[dev] Metrics: [0.33892617449664425, 0.38697318007662834, 0.30149253731343284] - [3, 4, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 4 - alpha: 0.7\n",
      "[dev] Metrics: [0.34724540901502504, 0.3939393939393939, 0.31044776119402984] - [3, 4, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 4 - alpha: 0.8\n",
      "[dev] Metrics: [0.3289473684210526, 0.3663003663003663, 0.29850746268656714] - [3, 4, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 4 - alpha: 0.9\n",
      "[dev] Metrics: [0.31561996779388085, 0.34265734265734266, 0.29253731343283584] - [3, 4, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 4 - alpha: 1\n",
      "[dev] Metrics: [0.2375601926163724, 0.2569444444444444, 0.2208955223880597] - [3, 4, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 5 - alpha: 0.5\n",
      "[dev] Metrics: [0.3400673400673401, 0.38996138996138996, 0.30149253731343284] - [3, 5, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 5 - alpha: 0.6\n",
      "[dev] Metrics: [0.34, 0.3849056603773585, 0.3044776119402985] - [3, 5, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 5 - alpha: 0.7\n",
      "[dev] Metrics: [0.34596375617792424, 0.3860294117647059, 0.31343283582089554] - [3, 5, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 5 - alpha: 0.8\n",
      "[dev] Metrics: [0.3295269168026101, 0.36330935251798563, 0.30149253731343284] - [3, 5, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 5 - alpha: 0.9\n",
      "[dev] Metrics: [0.31460674157303375, 0.3402777777777778, 0.29253731343283584] - [3, 5, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 5 - alpha: 1\n",
      "[dev] Metrics: [0.2375601926163724, 0.2569444444444444, 0.2208955223880597] - [3, 5, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 6 - alpha: 0.5\n",
      "[dev] Metrics: [0.34056761268781305, 0.38636363636363635, 0.3044776119402985] - [3, 6, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 6 - alpha: 0.6\n",
      "[dev] Metrics: [0.3393739703459638, 0.3786764705882353, 0.3074626865671642] - [3, 6, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 6 - alpha: 0.7\n",
      "[dev] Metrics: [0.3453947368421053, 0.38461538461538464, 0.31343283582089554] - [3, 6, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 6 - alpha: 0.8\n",
      "[dev] Metrics: [0.3268608414239482, 0.3568904593639576, 0.30149253731343284] - [3, 6, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 6 - alpha: 0.9\n",
      "[dev] Metrics: [0.31460674157303375, 0.3402777777777778, 0.29253731343283584] - [3, 6, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 6 - alpha: 1\n",
      "[dev] Metrics: [0.2375601926163724, 0.2569444444444444, 0.2208955223880597] - [3, 6, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 7 - alpha: 0.5\n",
      "[dev] Metrics: [0.33993399339933994, 0.3800738007380074, 0.3074626865671642] - [3, 7, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 7 - alpha: 0.6\n",
      "[dev] Metrics: [0.3393739703459638, 0.3786764705882353, 0.3074626865671642] - [3, 7, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 7 - alpha: 0.7\n",
      "[dev] Metrics: [0.34584013050570966, 0.381294964028777, 0.3164179104477612] - [3, 7, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 7 - alpha: 0.8\n",
      "[dev] Metrics: [0.32633279483037164, 0.35563380281690143, 0.30149253731343284] - [3, 7, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 7 - alpha: 0.9\n",
      "[dev] Metrics: [0.31460674157303375, 0.3402777777777778, 0.29253731343283584] - [3, 7, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 7 - alpha: 1\n",
      "[dev] Metrics: [0.2375601926163724, 0.2569444444444444, 0.2208955223880597] - [3, 7, 1]\n",
      "\n",
      "[dev] k: 3 - margin: 8 - alpha: 0.5\n",
      "[dev] Metrics: [0.3393739703459638, 0.3786764705882353, 0.3074626865671642] - [3, 8, 0.5]\n",
      "\n",
      "[dev] k: 3 - margin: 8 - alpha: 0.6\n",
      "[dev] Metrics: [0.3382594417077176, 0.3759124087591241, 0.3074626865671642] - [3, 8, 0.6]\n",
      "\n",
      "[dev] k: 3 - margin: 8 - alpha: 0.7\n",
      "[dev] Metrics: [0.34527687296416937, 0.37992831541218636, 0.3164179104477612] - [3, 8, 0.7]\n",
      "\n",
      "[dev] k: 3 - margin: 8 - alpha: 0.8\n",
      "[dev] Metrics: [0.32633279483037164, 0.35563380281690143, 0.30149253731343284] - [3, 8, 0.8]\n",
      "\n",
      "[dev] k: 3 - margin: 8 - alpha: 0.9\n",
      "[dev] Metrics: [0.31460674157303375, 0.3402777777777778, 0.29253731343283584] - [3, 8, 0.9]\n",
      "\n",
      "[dev] k: 3 - margin: 8 - alpha: 1\n",
      "[dev] Metrics: [0.2375601926163724, 0.2569444444444444, 0.2208955223880597] - [3, 8, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 0 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [4, 0, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 0 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [4, 0, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 0 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [4, 0, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 0 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [4, 0, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 0 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [4, 0, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 0 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [4, 0, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 1 - alpha: 0.5\n",
      "[dev] Metrics: [0.3092369477911647, 0.4723926380368098, 0.2298507462686567] - [4, 1, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 1 - alpha: 0.6\n",
      "[dev] Metrics: [0.31128404669260695, 0.44692737430167595, 0.23880597014925373] - [4, 1, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 1 - alpha: 0.7\n",
      "[dev] Metrics: [0.29739776951672864, 0.39408866995073893, 0.23880597014925373] - [4, 1, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 1 - alpha: 0.8\n",
      "[dev] Metrics: [0.3269565217391305, 0.39166666666666666, 0.28059701492537314] - [4, 1, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 1 - alpha: 0.9\n",
      "[dev] Metrics: [0.31761006289308175, 0.33554817275747506, 0.30149253731343284] - [4, 1, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 1 - alpha: 1\n",
      "[dev] Metrics: [0.2559774964838256, 0.24202127659574468, 0.2716417910447761] - [4, 1, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 2 - alpha: 0.5\n",
      "[dev] Metrics: [0.31521739130434784, 0.4009216589861751, 0.25970149253731345] - [4, 2, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 2 - alpha: 0.6\n",
      "[dev] Metrics: [0.32246998284734135, 0.3790322580645161, 0.28059701492537314] - [4, 2, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 2 - alpha: 0.7\n",
      "[dev] Metrics: [0.34304207119741104, 0.3745583038869258, 0.3164179104477612] - [4, 2, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 2 - alpha: 0.8\n",
      "[dev] Metrics: [0.3363914373088685, 0.3448275862068966, 0.3283582089552239] - [4, 2, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 2 - alpha: 0.9\n",
      "[dev] Metrics: [0.3188405797101449, 0.30985915492957744, 0.3283582089552239] - [4, 2, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 2 - alpha: 1\n",
      "[dev] Metrics: [0.25383542538354253, 0.23821989528795812, 0.2716417910447761] - [4, 2, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 3 - alpha: 0.5\n",
      "[dev] Metrics: [0.31766612641815234, 0.3475177304964539, 0.29253731343283584] - [4, 3, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 3 - alpha: 0.6\n",
      "[dev] Metrics: [0.3276661514683153, 0.33974358974358976, 0.3164179104477612] - [4, 3, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 3 - alpha: 0.7\n",
      "[dev] Metrics: [0.3398496240601504, 0.3424242424242424, 0.3373134328358209] - [4, 3, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 3 - alpha: 0.8\n",
      "[dev] Metrics: [0.33918128654970764, 0.332378223495702, 0.34626865671641793] - [4, 3, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 3 - alpha: 0.9\n",
      "[dev] Metrics: [0.31444759206798867, 0.2991913746630728, 0.33134328358208953] - [4, 3, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 3 - alpha: 1\n",
      "[dev] Metrics: [0.2531293463143254, 0.23697916666666666, 0.2716417910447761] - [4, 3, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 4 - alpha: 0.5\n",
      "[dev] Metrics: [0.32973805855161786, 0.34076433121019106, 0.3194029850746269] - [4, 4, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 4 - alpha: 0.6\n",
      "[dev] Metrics: [0.32585949177877427, 0.3263473053892216, 0.3253731343283582] - [4, 4, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 4 - alpha: 0.7\n",
      "[dev] Metrics: [0.33628318584070793, 0.3323615160349854, 0.3402985074626866] - [4, 4, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 4 - alpha: 0.8\n",
      "[dev] Metrics: [0.3342939481268012, 0.3231197771587744, 0.34626865671641793] - [4, 4, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 4 - alpha: 0.9\n",
      "[dev] Metrics: [0.31328671328671326, 0.29473684210526313, 0.33432835820895523] - [4, 4, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 4 - alpha: 1\n",
      "[dev] Metrics: [0.2531293463143254, 0.23697916666666666, 0.2716417910447761] - [4, 4, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 5 - alpha: 0.5\n",
      "[dev] Metrics: [0.32934131736526945, 0.3303303303303303, 0.3283582089552239] - [4, 5, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 5 - alpha: 0.6\n",
      "[dev] Metrics: [0.3244837758112094, 0.3206997084548105, 0.3283582089552239] - [4, 5, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 5 - alpha: 0.7\n",
      "[dev] Metrics: [0.3376623376623377, 0.3268156424581006, 0.3492537313432836] - [4, 5, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 5 - alpha: 0.8\n",
      "[dev] Metrics: [0.333808844507846, 0.319672131147541, 0.3492537313432836] - [4, 5, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 5 - alpha: 0.9\n",
      "[dev] Metrics: [0.31476323119777155, 0.2950391644908616, 0.3373134328358209] - [4, 5, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 5 - alpha: 1\n",
      "[dev] Metrics: [0.2531293463143254, 0.23697916666666666, 0.2716417910447761] - [4, 5, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 6 - alpha: 0.5\n",
      "[dev] Metrics: [0.32791728212703103, 0.32456140350877194, 0.33134328358208953] - [4, 6, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 6 - alpha: 0.6\n",
      "[dev] Metrics: [0.32416787264833574, 0.3146067415730337, 0.33432835820895523] - [4, 6, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 6 - alpha: 0.7\n",
      "[dev] Metrics: [0.33717579250720464, 0.32590529247910865, 0.3492537313432836] - [4, 6, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 6 - alpha: 0.8\n",
      "[dev] Metrics: [0.3295774647887324, 0.312, 0.3492537313432836] - [4, 6, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 6 - alpha: 0.9\n",
      "[dev] Metrics: [0.3143254520166898, 0.2942708333333333, 0.3373134328358209] - [4, 6, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 6 - alpha: 1\n",
      "[dev] Metrics: [0.2531293463143254, 0.23697916666666666, 0.2716417910447761] - [4, 6, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 7 - alpha: 0.5\n",
      "[dev] Metrics: [0.32558139534883723, 0.31728045325779036, 0.33432835820895523] - [4, 7, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 7 - alpha: 0.6\n",
      "[dev] Metrics: [0.3232323232323232, 0.3128491620111732, 0.33432835820895523] - [4, 7, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 7 - alpha: 0.7\n",
      "[dev] Metrics: [0.33714285714285713, 0.3232876712328767, 0.3522388059701492] - [4, 7, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 7 - alpha: 0.8\n",
      "[dev] Metrics: [0.32819074333800846, 0.30952380952380953, 0.3492537313432836] - [4, 7, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 7 - alpha: 0.9\n",
      "[dev] Metrics: [0.3143254520166898, 0.2942708333333333, 0.3373134328358209] - [4, 7, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 7 - alpha: 1\n",
      "[dev] Metrics: [0.2531293463143254, 0.23697916666666666, 0.2716417910447761] - [4, 7, 1]\n",
      "\n",
      "[dev] k: 4 - margin: 8 - alpha: 0.5\n",
      "[dev] Metrics: [0.3261183261183261, 0.31564245810055863, 0.3373134328358209] - [4, 8, 0.5]\n",
      "\n",
      "[dev] k: 4 - margin: 8 - alpha: 0.6\n",
      "[dev] Metrics: [0.32230215827338127, 0.3111111111111111, 0.33432835820895523] - [4, 8, 0.6]\n",
      "\n",
      "[dev] k: 4 - margin: 8 - alpha: 0.7\n",
      "[dev] Metrics: [0.3357041251778094, 0.32065217391304346, 0.3522388059701492] - [4, 8, 0.7]\n",
      "\n",
      "[dev] k: 4 - margin: 8 - alpha: 0.8\n",
      "[dev] Metrics: [0.32819074333800846, 0.30952380952380953, 0.3492537313432836] - [4, 8, 0.8]\n",
      "\n",
      "[dev] k: 4 - margin: 8 - alpha: 0.9\n",
      "[dev] Metrics: [0.3143254520166898, 0.2942708333333333, 0.3373134328358209] - [4, 8, 0.9]\n",
      "\n",
      "[dev] k: 4 - margin: 8 - alpha: 1\n",
      "[dev] Metrics: [0.2531293463143254, 0.23697916666666666, 0.2716417910447761] - [4, 8, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 0 - alpha: 0.5\n",
      "[dev] Metrics: [0.21809744779582366, 0.4895833333333333, 0.14029850746268657] - [5, 0, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 0 - alpha: 0.6\n",
      "[dev] Metrics: [0.23201856148491876, 0.5208333333333334, 0.14925373134328357] - [5, 0, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 0 - alpha: 0.7\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [5, 0, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 0 - alpha: 0.8\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [5, 0, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 0 - alpha: 0.9\n",
      "[dev] Metrics: [0.24129930394431554, 0.5416666666666666, 0.15522388059701492] - [5, 0, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 0 - alpha: 1\n",
      "[dev] Metrics: [0.12064965197215777, 0.2708333333333333, 0.07761194029850746] - [5, 0, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 1 - alpha: 0.5\n",
      "[dev] Metrics: [0.31137724550898205, 0.46987951807228917, 0.23283582089552238] - [5, 1, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 1 - alpha: 0.6\n",
      "[dev] Metrics: [0.3206106870229008, 0.4444444444444444, 0.2507462686567164] - [5, 1, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 1 - alpha: 0.7\n",
      "[dev] Metrics: [0.31654676258992803, 0.39819004524886875, 0.2626865671641791] - [5, 1, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 1 - alpha: 0.8\n",
      "[dev] Metrics: [0.34049586776859503, 0.3814814814814815, 0.3074626865671642] - [5, 1, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 1 - alpha: 0.9\n",
      "[dev] Metrics: [0.32706222865412443, 0.31741573033707865, 0.3373134328358209] - [5, 1, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 1 - alpha: 1\n",
      "[dev] Metrics: [0.2631578947368421, 0.2267818574514039, 0.31343283582089554] - [5, 1, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 2 - alpha: 0.5\n",
      "[dev] Metrics: [0.33043478260869563, 0.3958333333333333, 0.2835820895522388] - [5, 2, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 2 - alpha: 0.6\n",
      "[dev] Metrics: [0.3404255319148936, 0.37681159420289856, 0.31044776119402984] - [5, 2, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 2 - alpha: 0.7\n",
      "[dev] Metrics: [0.35347432024169184, 0.3577981651376147, 0.3492537313432836] - [5, 2, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 2 - alpha: 0.8\n",
      "[dev] Metrics: [0.3450210378681627, 0.3253968253968254, 0.36716417910447763] - [5, 2, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 2 - alpha: 0.9\n",
      "[dev] Metrics: [0.3255208333333333, 0.28868360277136257, 0.373134328358209] - [5, 2, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 2 - alpha: 1\n",
      "[dev] Metrics: [0.25862068965517243, 0.22012578616352202, 0.31343283582089554] - [5, 2, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 3 - alpha: 0.5\n",
      "[dev] Metrics: [0.33384379785604895, 0.34276729559748426, 0.3253731343283582] - [5, 3, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 3 - alpha: 0.6\n",
      "[dev] Metrics: [0.3357245337159254, 0.32320441988950277, 0.3492537313432836] - [5, 3, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 3 - alpha: 0.7\n",
      "[dev] Metrics: [0.34615384615384615, 0.32061068702290074, 0.3761194029850746] - [5, 3, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 3 - alpha: 0.8\n",
      "[dev] Metrics: [0.3425559947299078, 0.30660377358490565, 0.3880597014925373] - [5, 3, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 3 - alpha: 0.9\n",
      "[dev] Metrics: [0.3198992443324937, 0.2766884531590414, 0.37910447761194027] - [5, 3, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 3 - alpha: 1\n",
      "[dev] Metrics: [0.2576687116564417, 0.21875, 0.31343283582089554] - [5, 3, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 4 - alpha: 0.5\n",
      "[dev] Metrics: [0.33663366336633666, 0.31989247311827956, 0.35522388059701493] - [5, 4, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 4 - alpha: 0.6\n",
      "[dev] Metrics: [0.3342391304347826, 0.30673316708229426, 0.36716417910447763] - [5, 4, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 4 - alpha: 0.7\n",
      "[dev] Metrics: [0.3421750663129974, 0.30787589498806683, 0.3850746268656716] - [5, 4, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 4 - alpha: 0.8\n",
      "[dev] Metrics: [0.3388960205391528, 0.2972972972972973, 0.3940298507462687] - [5, 4, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 4 - alpha: 0.9\n",
      "[dev] Metrics: [0.31683168316831684, 0.27061310782241016, 0.382089552238806] - [5, 4, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 4 - alpha: 1\n",
      "[dev] Metrics: [0.2576687116564417, 0.21875, 0.31343283582089554] - [5, 4, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 5 - alpha: 0.5\n",
      "[dev] Metrics: [0.33695652173913043, 0.3092269326683292, 0.3701492537313433] - [5, 5, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 5 - alpha: 0.6\n",
      "[dev] Metrics: [0.3293492695883134, 0.2966507177033493, 0.3701492537313433] - [5, 5, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 5 - alpha: 0.7\n",
      "[dev] Metrics: [0.3406451612903226, 0.3, 0.3940298507462687] - [5, 5, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 5 - alpha: 0.8\n",
      "[dev] Metrics: [0.33967046894803554, 0.29515418502202645, 0.4] - [5, 5, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 5 - alpha: 0.9\n",
      "[dev] Metrics: [0.31734317343173435, 0.2698744769874477, 0.3850746268656716] - [5, 5, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 5 - alpha: 1\n",
      "[dev] Metrics: [0.2576687116564417, 0.21875, 0.31343283582089554] - [5, 5, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 6 - alpha: 0.5\n",
      "[dev] Metrics: [0.3324468085106383, 0.2997601918465228, 0.373134328358209] - [5, 6, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 6 - alpha: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/319 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dev] Metrics: [0.3290155440414508, 0.2906178489702517, 0.37910447761194027] - [5, 6, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 6 - alpha: 0.7\n",
      "[dev] Metrics: [0.3384615384615384, 0.2966292134831461, 0.3940298507462687] - [5, 6, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 6 - alpha: 0.8\n",
      "[dev] Metrics: [0.33541927409261574, 0.28879310344827586, 0.4] - [5, 6, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 6 - alpha: 0.9\n",
      "[dev] Metrics: [0.3165644171779141, 0.26875, 0.3850746268656716] - [5, 6, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 6 - alpha: 1\n",
      "[dev] Metrics: [0.2576687116564417, 0.21875, 0.31343283582089554] - [5, 6, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 7 - alpha: 0.5\n",
      "[dev] Metrics: [0.3311603650586701, 0.29398148148148145, 0.37910447761194027] - [5, 7, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 7 - alpha: 0.6\n",
      "[dev] Metrics: [0.327319587628866, 0.28798185941043086, 0.37910447761194027] - [5, 7, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 7 - alpha: 0.7\n",
      "[dev] Metrics: [0.337992376111817, 0.2942477876106195, 0.3970149253731343] - [5, 7, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 7 - alpha: 0.8\n",
      "[dev] Metrics: [0.3325062034739454, 0.28450106157112526, 0.4] - [5, 7, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 7 - alpha: 0.9\n",
      "[dev] Metrics: [0.3165644171779141, 0.26875, 0.3850746268656716] - [5, 7, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 7 - alpha: 1\n",
      "[dev] Metrics: [0.2576687116564417, 0.21875, 0.31343283582089554] - [5, 7, 1]\n",
      "\n",
      "[dev] k: 5 - margin: 8 - alpha: 0.5\n",
      "[dev] Metrics: [0.32989690721649484, 0.29024943310657597, 0.382089552238806] - [5, 8, 0.5]\n",
      "\n",
      "[dev] k: 5 - margin: 8 - alpha: 0.6\n",
      "[dev] Metrics: [0.32522407170294493, 0.28475336322869954, 0.37910447761194027] - [5, 8, 0.6]\n",
      "\n",
      "[dev] k: 5 - margin: 8 - alpha: 0.7\n",
      "[dev] Metrics: [0.3383838383838384, 0.29321663019693656, 0.4] - [5, 8, 0.7]\n",
      "\n",
      "[dev] k: 5 - margin: 8 - alpha: 0.8\n",
      "[dev] Metrics: [0.33209417596034696, 0.2838983050847458, 0.4] - [5, 8, 0.8]\n",
      "\n",
      "[dev] k: 5 - margin: 8 - alpha: 0.9\n",
      "[dev] Metrics: [0.3165644171779141, 0.26875, 0.3850746268656716] - [5, 8, 0.9]\n",
      "\n",
      "[dev] k: 5 - margin: 8 - alpha: 1\n",
      "[dev] Metrics: [0.2576687116564417, 0.21875, 0.31343283582089554] - [5, 8, 1]\n",
      "[dev] Best metrics: [0.35347432024169184, 0.3577981651376147, 0.3492537313432836] - [5, 2, 0.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 319/319 [00:53<00:00,  5.99it/s]\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                  | 127/319 [03:28<05:16,  1.65s/it]"
     ]
    }
   ],
   "source": [
    "with open('dataset/c2023/bm25_candidates_dev_50.json', 'r') as fp:\n",
    "    candidate_dict = json.load(fp)\n",
    "\n",
    "eval_bm25_end_model(\n",
    "    bm25_index_path='bm25/dev',\n",
    "    candidate_dict=candidate_dict,\n",
    "    ckpt_path='train_logs/monot5-large-10k_hns/ckpt/checkpoint-938',\n",
    "    eval_segment='dev',\n",
    "    model_class='monot5'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
