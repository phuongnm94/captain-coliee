{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "os.chdir('/home/s2310409/workspace/coliee-2024/')\n",
    "\n",
    "def load_data(dir):\n",
    "    with open(dir, 'r') as fp:\n",
    "        train_data = json.load(fp)\n",
    "\n",
    "    data = []\n",
    "    for key in train_data.keys():\n",
    "        data.append([key, train_data[key]])\n",
    "\n",
    "    return pd.DataFrame(data, columns=['source', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25 Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(sentences, window_size=10):\n",
    "    chunks = []\n",
    "    for i in range(0, len(sentences) - window_size, window_size//2):\n",
    "        chunks.append(\"\\n\".join(sentences[i:i+window_size]))\n",
    "    return chunks\n",
    "\n",
    "with open('dataset/all_data.json') as f:\n",
    "    all_data_dict = json.load(f)\n",
    "\n",
    "word_tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# file_list = sorted(list(all_data_dict.keys()))\n",
    "\n",
    "file_list = [f for f in os.listdir('dataset/c2023/test_files') if f.endswith('.txt')]\n",
    "file_list = [f for f in file_list if f in all_data_dict.keys()]\n",
    "file_list = sorted(file_list)\n",
    "\n",
    "processed_file_dict = {}\n",
    "for file in [f for f in os.listdir('dataset/processed') if not f.startswith('.')]:\n",
    "    processed_file = f\"dataset/processed/{file}\"\n",
    "    with open(processed_file, 'r') as fp:\n",
    "        processed_document = fp.read()\n",
    "        processed_file_dict[file] = {\n",
    "            'sentences': processed_document.split('\\n\\n'),\n",
    "            'processed_document': processed_document\n",
    "        }\n",
    "\n",
    "chunk_dict = {}\n",
    "for file in file_list:\n",
    "    chunks = chunking(processed_file_dict[file]['sentences'])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if len(chunk) > 0:\n",
    "            chunk_dict[f\"{file}_{i}\"] = chunk\n",
    "\n",
    "mode = 'document'\n",
    "if mode == 'chunk':\n",
    "    # bm25 for chunks\n",
    "    corpus = []\n",
    "    chunk_list = sorted(list(chunk_dict.keys()))\n",
    "    for chunk in chunk_list:\n",
    "        corpus.append(chunk_dict[chunk])\n",
    "    tokenized_corpus = [word_tokenizer.tokenize(doc) for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "else:\n",
    "    # bm25 for whole document\n",
    "    corpus = []\n",
    "    prcessed_list = sorted(file_list)\n",
    "    for file in prcessed_list:\n",
    "        corpus.append(processed_file_dict[file]['processed_document'])\n",
    "    tokenized_corpus = [word_tokenizer.tokenize(doc) for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query with TF-IDF keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "docs = []\n",
    "for file in processed_file_dict.keys():\n",
    "    docs.append(processed_file_dict[file]['processed_document'])\n",
    "\n",
    "count_vec = CountVectorizer(stop_words=stopwords)\n",
    "word_count_vector = count_vec.fit_transform(docs)\n",
    "\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "features = count_vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Query on chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1217/1217 [00:04<00:00, 303.80it/s]\n",
      "  0%|                                                                                                                                                                                                                                 | 0/1217 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chunk_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m results \u001b[38;5;241m=\u001b[39m bm25\u001b[38;5;241m.\u001b[39mget_scores(tokenized_query)\n\u001b[1;32m     22\u001b[0m max_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(results)[\u001b[38;5;241m-\u001b[39mn_candidates:]\n\u001b[0;32m---> 24\u001b[0m chunk_candidates \u001b[38;5;241m=\u001b[39m [chunk_list[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m max_ids]\n\u001b[1;32m     25\u001b[0m chunk_candidate_dict[file] \u001b[38;5;241m=\u001b[39m chunk_candidates\n\u001b[1;32m     27\u001b[0m document_candidates \u001b[38;5;241m=\u001b[39m [chunk\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_candidates]\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m results \u001b[38;5;241m=\u001b[39m bm25\u001b[38;5;241m.\u001b[39mget_scores(tokenized_query)\n\u001b[1;32m     22\u001b[0m max_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(results)[\u001b[38;5;241m-\u001b[39mn_candidates:]\n\u001b[0;32m---> 24\u001b[0m chunk_candidates \u001b[38;5;241m=\u001b[39m [\u001b[43mchunk_list\u001b[49m[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m max_ids]\n\u001b[1;32m     25\u001b[0m chunk_candidate_dict[file] \u001b[38;5;241m=\u001b[39m chunk_candidates\n\u001b[1;32m     27\u001b[0m document_candidates \u001b[38;5;241m=\u001b[39m [chunk\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_candidates]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunk_list' is not defined"
     ]
    }
   ],
   "source": [
    "n_keywords = 25\n",
    "\n",
    "def extract_query(doc):\n",
    "    tf_idf_vector=tfidf_transformer.transform(count_vec.transform([doc]))\n",
    "    sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
    "    keywords=extract_topn_from_vector(features,sorted_items, n_keywords)\n",
    "    return \" \".join(list(keywords.keys()))\n",
    "\n",
    "query_dict = {}\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    query_dict[file] = extract_query(processed_file_dict[file]['processed_document'])\n",
    "\n",
    "n_candidates = 50\n",
    "chunk_candidate_dict = {}\n",
    "candidate_dict = {}\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    query = query_dict[file]\n",
    "    tokenized_query = word_tokenizer.tokenize(query)\n",
    "    results = bm25.get_scores(tokenized_query)\n",
    "    max_ids = np.argsort(results)[-n_candidates:]\n",
    "\n",
    "    chunk_candidates = [chunk_list[idx] for idx in max_ids]\n",
    "    chunk_candidate_dict[file] = chunk_candidates\n",
    "\n",
    "    document_candidates = [chunk.split('_')[0] for chunk in chunk_candidates]\n",
    "    candidate_dict[file] = list(set(document_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df = load_data('dataset/json/test.json')\n",
    "\n",
    "test_df['chunk_candidates'] = test_df['source'].apply(lambda x: chunk_candidate_dict[x])\n",
    "test_df['candidates'] = test_df['source'].apply(lambda x: candidate_dict[x])\n",
    "test_df['query'] = test_df['source'].apply(lambda x: query_dict[x])\n",
    "\n",
    "# calculate accuracy metrics for BM25 + TF-IDF\n",
    "correct = 0\n",
    "n_retrived = 0\n",
    "n_relevant = 0\n",
    "\n",
    "coverages = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    preds = row['candidates']\n",
    "    coverages.append(len(preds))\n",
    "    n_retrived += len(preds)\n",
    "    n_relevant += len(target)\n",
    "    for prediction in preds:\n",
    "        if prediction in target:\n",
    "            correct += 1\n",
    "\n",
    "precision = correct / n_retrived\n",
    "recall = correct / n_relevant\n",
    "\n",
    "print(f\"Average # candidates: {np.mean(coverages)}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {2 * precision * recall / (precision + recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>chunk_candidates</th>\n",
       "      <th>candidates</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>070318.txt</td>\n",
       "      <td>[015076.txt]</td>\n",
       "      <td>[026517.txt_0, 084131.txt_5, 025676.txt_12, 04...</td>\n",
       "      <td>[010714.txt, 054863.txt, 037739.txt, 093796.tx...</td>\n",
       "      <td>rpo board guideline adamidis applicant france ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>077960.txt</td>\n",
       "      <td>[009054.txt, 040860.txt]</td>\n",
       "      <td>[071670.txt_5, 079542.txt_3, 015274.txt_1, 055...</td>\n",
       "      <td>[077828.txt, 010714.txt, 048551.txt, 040860.tx...</td>\n",
       "      <td>removal child children custody order dunn cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>042319.txt</td>\n",
       "      <td>[093691.txt, 075956.txt, 084953.txt, 022987.txt]</td>\n",
       "      <td>[094702.txt_6, 031573.txt_1, 017268.txt_2, 024...</td>\n",
       "      <td>[087571.txt, 020300.txt, 042893.txt, 046082.tx...</td>\n",
       "      <td>beyer cross affidavit prothonotary examination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041766.txt</td>\n",
       "      <td>[039269.txt]</td>\n",
       "      <td>[098992.txt_10, 079863.txt_2, 084744.txt_1, 02...</td>\n",
       "      <td>[023186.txt, 077828.txt, 084744.txt, 028729.tx...</td>\n",
       "      <td>drug clinical nds health data 002 omitted 08 n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>077407.txt</td>\n",
       "      <td>[038669.txt]</td>\n",
       "      <td>[010486.txt_4, 063976.txt_3, 077407.txt_8, 021...</td>\n",
       "      <td>[087571.txt, 039348.txt, 010486.txt, 021955.tx...</td>\n",
       "      <td>communication 23 privilege counsel litigation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>085079.txt</td>\n",
       "      <td>[044669.txt, 003144.txt]</td>\n",
       "      <td>[030514.txt_6, 084937.txt_4, 060581.txt_14, 07...</td>\n",
       "      <td>[039348.txt, 025162.txt, 084937.txt, 022837.tx...</td>\n",
       "      <td>cso promotions shephard cst adjudicator commis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>031370.txt</td>\n",
       "      <td>[096341.txt, 060602.txt, 047107.txt, 084522.tx...</td>\n",
       "      <td>[000084.txt_0, 047826.txt_3, 094010.txt_0, 048...</td>\n",
       "      <td>[023186.txt, 077828.txt, 027678.txt, 048551.tx...</td>\n",
       "      <td>removal peru applicant irreparable 3d spouse p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>085828.txt</td>\n",
       "      <td>[004301.txt, 074887.txt, 088994.txt]</td>\n",
       "      <td>[035451.txt_8, 063976.txt_5, 060350.txt_6, 091...</td>\n",
       "      <td>[088994.txt, 071670.txt, 028315.txt, 063976.tx...</td>\n",
       "      <td>officer applicants india singh riots risk prra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>024957.txt</td>\n",
       "      <td>[015009.txt, 080348.txt]</td>\n",
       "      <td>[052545.txt_4, 002842.txt_9, 081064.txt_3, 087...</td>\n",
       "      <td>[055800.txt, 080348.txt, 077315.txt, 058746.tx...</td>\n",
       "      <td>seizure annuity civil 224 code debtor chattels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>060678.txt</td>\n",
       "      <td>[018625.txt]</td>\n",
       "      <td>[095735.txt_5, 019075.txt_2, 092750.txt_6, 024...</td>\n",
       "      <td>[059067.txt, 068642.txt, 058746.txt, 093675.tx...</td>\n",
       "      <td>industrial jurisdiction infringement plaintiff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source                                             target  \\\n",
       "0    070318.txt                                       [015076.txt]   \n",
       "1    077960.txt                           [009054.txt, 040860.txt]   \n",
       "2    042319.txt   [093691.txt, 075956.txt, 084953.txt, 022987.txt]   \n",
       "3    041766.txt                                       [039269.txt]   \n",
       "4    077407.txt                                       [038669.txt]   \n",
       "..          ...                                                ...   \n",
       "314  085079.txt                           [044669.txt, 003144.txt]   \n",
       "315  031370.txt  [096341.txt, 060602.txt, 047107.txt, 084522.tx...   \n",
       "316  085828.txt               [004301.txt, 074887.txt, 088994.txt]   \n",
       "317  024957.txt                           [015009.txt, 080348.txt]   \n",
       "318  060678.txt                                       [018625.txt]   \n",
       "\n",
       "                                      chunk_candidates  \\\n",
       "0    [026517.txt_0, 084131.txt_5, 025676.txt_12, 04...   \n",
       "1    [071670.txt_5, 079542.txt_3, 015274.txt_1, 055...   \n",
       "2    [094702.txt_6, 031573.txt_1, 017268.txt_2, 024...   \n",
       "3    [098992.txt_10, 079863.txt_2, 084744.txt_1, 02...   \n",
       "4    [010486.txt_4, 063976.txt_3, 077407.txt_8, 021...   \n",
       "..                                                 ...   \n",
       "314  [030514.txt_6, 084937.txt_4, 060581.txt_14, 07...   \n",
       "315  [000084.txt_0, 047826.txt_3, 094010.txt_0, 048...   \n",
       "316  [035451.txt_8, 063976.txt_5, 060350.txt_6, 091...   \n",
       "317  [052545.txt_4, 002842.txt_9, 081064.txt_3, 087...   \n",
       "318  [095735.txt_5, 019075.txt_2, 092750.txt_6, 024...   \n",
       "\n",
       "                                            candidates  \\\n",
       "0    [010714.txt, 054863.txt, 037739.txt, 093796.tx...   \n",
       "1    [077828.txt, 010714.txt, 048551.txt, 040860.tx...   \n",
       "2    [087571.txt, 020300.txt, 042893.txt, 046082.tx...   \n",
       "3    [023186.txt, 077828.txt, 084744.txt, 028729.tx...   \n",
       "4    [087571.txt, 039348.txt, 010486.txt, 021955.tx...   \n",
       "..                                                 ...   \n",
       "314  [039348.txt, 025162.txt, 084937.txt, 022837.tx...   \n",
       "315  [023186.txt, 077828.txt, 027678.txt, 048551.tx...   \n",
       "316  [088994.txt, 071670.txt, 028315.txt, 063976.tx...   \n",
       "317  [055800.txt, 080348.txt, 077315.txt, 058746.tx...   \n",
       "318  [059067.txt, 068642.txt, 058746.txt, 093675.tx...   \n",
       "\n",
       "                                                 query  \n",
       "0    rpo board guideline adamidis applicant france ...  \n",
       "1    removal child children custody order dunn cour...  \n",
       "2    beyer cross affidavit prothonotary examination...  \n",
       "3    drug clinical nds health data 002 omitted 08 n...  \n",
       "4    communication 23 privilege counsel litigation ...  \n",
       "..                                                 ...  \n",
       "314  cso promotions shephard cst adjudicator commis...  \n",
       "315  removal peru applicant irreparable 3d spouse p...  \n",
       "316  officer applicants india singh riots risk prra...  \n",
       "317  seizure annuity civil 224 code debtor chattels...  \n",
       "318  industrial jurisdiction infringement plaintiff...  \n",
       "\n",
       "[319 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query on all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1217/1217 [00:04<00:00, 303.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1217/1217 [00:08<00:00, 136.37it/s]\n"
     ]
    }
   ],
   "source": [
    "n_keywords = 25\n",
    "\n",
    "def extract_query(doc):\n",
    "    tf_idf_vector=tfidf_transformer.transform(count_vec.transform([doc]))\n",
    "    sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
    "    keywords=extract_topn_from_vector(features,sorted_items, n_keywords)\n",
    "    return \" \".join(list(keywords.keys()))\n",
    "\n",
    "query_dict = {}\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    query_dict[file] = extract_query(processed_file_dict[file]['processed_document'])\n",
    "\n",
    "n_candidates = 50\n",
    "candidate_dicts = {}\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    query = query_dict[file]\n",
    "    tokenized_query = word_tokenizer.tokenize(query)\n",
    "    results = bm25.get_scores(tokenized_query)\n",
    "    max_ids = np.argsort(results)[-n_candidates:]\n",
    "    document_candidates = [file_list[idx] for idx in max_ids]\n",
    "    candidate_dicts[file] = list(set(document_candidates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # candidates: 50.0\n",
      "Precision: 0.0374294670846395\n",
      "Recall: 0.7184115523465704\n",
      "F1: 0.07115189797985817\n"
     ]
    }
   ],
   "source": [
    "test_df = load_data('dataset/test.json')\n",
    "\n",
    "test_df['candidates'] = test_df['source'].apply(lambda x: candidate_dicts[x])\n",
    "test_df['query'] = test_df['source'].apply(lambda x: query_dict[x])\n",
    "\n",
    "# calculate accuracy metrics for BM25 + TF-IDF\n",
    "correct = 0\n",
    "n_retrived = 0\n",
    "n_relevant = 0\n",
    "\n",
    "coverages = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    preds = row['candidates']\n",
    "    coverages.append(len(preds))\n",
    "    n_retrived += len(preds)\n",
    "    n_relevant += len(target)\n",
    "    for prediction in preds:\n",
    "        if prediction in target:\n",
    "            correct += 1\n",
    "\n",
    "precision = correct / n_retrived\n",
    "recall = correct / n_relevant\n",
    "\n",
    "print(f\"Average # candidates: {np.mean(coverages)}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {2 * precision * recall / (precision + recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>candidates</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>070318.txt</td>\n",
       "      <td>[015076.txt]</td>\n",
       "      <td>[032432.txt, 020211.txt, 025676.txt, 073854.tx...</td>\n",
       "      <td>rpo board adamidis guideline applicant hearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>077960.txt</td>\n",
       "      <td>[009054.txt, 040860.txt]</td>\n",
       "      <td>[071412.txt, 019505.txt, 048551.txt, 026347.tx...</td>\n",
       "      <td>removal custody child children dunn order idah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>042319.txt</td>\n",
       "      <td>[093691.txt, 075956.txt, 084953.txt, 022987.txt]</td>\n",
       "      <td>[086059.txt, 093691.txt, 094451.txt, 019572.tx...</td>\n",
       "      <td>beyer cross affidavit prothonotary examination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041766.txt</td>\n",
       "      <td>[039269.txt]</td>\n",
       "      <td>[098992.txt, 091415.txt, 038039.txt, 084744.tx...</td>\n",
       "      <td>drug clinical nds 002 data health omitted 08 n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>077407.txt</td>\n",
       "      <td>[038669.txt]</td>\n",
       "      <td>[041415.txt, 085158.txt, 071211.txt, 030514.tx...</td>\n",
       "      <td>communication 23 privilege litigation counsel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>085079.txt</td>\n",
       "      <td>[044669.txt, 003144.txt]</td>\n",
       "      <td>[071211.txt, 085158.txt, 051660.txt, 078642.tx...</td>\n",
       "      <td>cso promotions shephard cst adjudicator jse co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>031370.txt</td>\n",
       "      <td>[096341.txt, 060602.txt, 047107.txt, 084522.tx...</td>\n",
       "      <td>[019505.txt, 096717.txt, 017883.txt, 084744.tx...</td>\n",
       "      <td>removal peru irreparable applicant 3d spouse p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>085828.txt</td>\n",
       "      <td>[004301.txt, 074887.txt, 088994.txt]</td>\n",
       "      <td>[019505.txt, 048551.txt, 049064.txt, 087722.tx...</td>\n",
       "      <td>officer applicants india singh riots principal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>024957.txt</td>\n",
       "      <td>[015009.txt, 080348.txt]</td>\n",
       "      <td>[098992.txt, 048208.txt, 078642.txt, 015009.tx...</td>\n",
       "      <td>annuity seizure civil 224 debtor code unseizab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>060678.txt</td>\n",
       "      <td>[018625.txt]</td>\n",
       "      <td>[051306.txt, 039650.txt, 050680.txt, 014639.tx...</td>\n",
       "      <td>industrial jurisdiction infringement plaintiff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source                                             target  \\\n",
       "0    070318.txt                                       [015076.txt]   \n",
       "1    077960.txt                           [009054.txt, 040860.txt]   \n",
       "2    042319.txt   [093691.txt, 075956.txt, 084953.txt, 022987.txt]   \n",
       "3    041766.txt                                       [039269.txt]   \n",
       "4    077407.txt                                       [038669.txt]   \n",
       "..          ...                                                ...   \n",
       "314  085079.txt                           [044669.txt, 003144.txt]   \n",
       "315  031370.txt  [096341.txt, 060602.txt, 047107.txt, 084522.tx...   \n",
       "316  085828.txt               [004301.txt, 074887.txt, 088994.txt]   \n",
       "317  024957.txt                           [015009.txt, 080348.txt]   \n",
       "318  060678.txt                                       [018625.txt]   \n",
       "\n",
       "                                            candidates  \\\n",
       "0    [032432.txt, 020211.txt, 025676.txt, 073854.tx...   \n",
       "1    [071412.txt, 019505.txt, 048551.txt, 026347.tx...   \n",
       "2    [086059.txt, 093691.txt, 094451.txt, 019572.tx...   \n",
       "3    [098992.txt, 091415.txt, 038039.txt, 084744.tx...   \n",
       "4    [041415.txt, 085158.txt, 071211.txt, 030514.tx...   \n",
       "..                                                 ...   \n",
       "314  [071211.txt, 085158.txt, 051660.txt, 078642.tx...   \n",
       "315  [019505.txt, 096717.txt, 017883.txt, 084744.tx...   \n",
       "316  [019505.txt, 048551.txt, 049064.txt, 087722.tx...   \n",
       "317  [098992.txt, 048208.txt, 078642.txt, 015009.tx...   \n",
       "318  [051306.txt, 039650.txt, 050680.txt, 014639.tx...   \n",
       "\n",
       "                                                 query  \n",
       "0    rpo board adamidis guideline applicant hearing...  \n",
       "1    removal custody child children dunn order idah...  \n",
       "2    beyer cross affidavit prothonotary examination...  \n",
       "3    drug clinical nds 002 data health omitted 08 n...  \n",
       "4    communication 23 privilege litigation counsel ...  \n",
       "..                                                 ...  \n",
       "314  cso promotions shephard cst adjudicator jse co...  \n",
       "315  removal peru irreparable applicant 3d spouse p...  \n",
       "316  officer applicants india singh riots principal...  \n",
       "317  annuity seizure civil 224 debtor code unseizab...  \n",
       "318  industrial jurisdiction infringement plaintiff...  \n",
       "\n",
       "[319 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
