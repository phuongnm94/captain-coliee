{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import copy\n",
    "import random\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import TrainerCallback, AutoTokenizer\n",
    "os.chdir('/home/s2310409/workspace/coliee-2024/')\n",
    "from utils.misc import get_query, get_summary\n",
    "\n",
    "\n",
    "def load_data(dir):\n",
    "    with open(dir, 'r') as fp:\n",
    "        train_data = json.load(fp)\n",
    "\n",
    "    data = []\n",
    "    for key in train_data.keys():\n",
    "        data.append([key, train_data[key]])\n",
    "\n",
    "    return pd.DataFrame(data, columns=['source', 'target'])\n",
    "\n",
    "def get_summary(doc_name):\n",
    "    with open(f\"dataset/mixtral_summarized/{doc_name}\", 'r') as fp:\n",
    "        summary = fp.read()\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(sentences, window_size=10):\n",
    "    chunks = []\n",
    "    for i in range(0, len(sentences) - window_size, window_size//2):\n",
    "        chunks.append(\"\\n\".join(sentences[i:i+window_size]))\n",
    "    return chunks\n",
    "\n",
    "word_tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# file_list = sorted(list(all_data_dict.keys()))\n",
    "\n",
    "split = 'dev'\n",
    "if split == 'dev':\n",
    "    file_list = []\n",
    "    with open(f'dataset/dev.json', 'r') as fp:\n",
    "        split_data = json.load(fp)\n",
    "        for file in split_data.keys():\n",
    "            file_list.append(file)\n",
    "            file_list.extend(split_data[file])\n",
    "    file_list = sorted(list(set(file_list)))\n",
    "elif split == 'test':\n",
    "    file_list = [f for f in os.listdir('dataset/c2023/test_files') if f.endswith('.txt')]\n",
    "    file_list = sorted(file_list)\n",
    "elif split == 'submission':\n",
    "    file_list = [f for f in os.listdir('dataset/c2024/test_files') if f.endswith('.txt')]\n",
    "    file_list = sorted(file_list)\n",
    "\n",
    "processed_file_dict = {}\n",
    "for file in [f for f in os.listdir('dataset/processed') if not f.startswith('.')]:\n",
    "    processed_file = f\"dataset/processed/{file}\"\n",
    "    with open(processed_file, 'r') as fp:\n",
    "        processed_document = fp.read()\n",
    "        processed_file_dict[file] = {\n",
    "            'sentences': processed_document.split('\\n\\n'),\n",
    "            'processed_document': processed_document\n",
    "        }\n",
    "\n",
    "chunk_dict = {}\n",
    "for file in file_list:\n",
    "    chunks = chunking(processed_file_dict[file]['sentences'])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if len(chunk) > 0:\n",
    "            chunk_dict[f\"{file}_{i}\"] = chunk\n",
    "\n",
    "mode = 'document'\n",
    "if mode == 'chunk':\n",
    "    # bm25 for chunks\n",
    "    corpus = []\n",
    "    chunk_list = sorted(list(chunk_dict.keys()))\n",
    "    for chunk in chunk_list:\n",
    "        corpus.append(chunk_dict[chunk])\n",
    "    tokenized_corpus = [word_tokenizer.tokenize(doc) for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "else:\n",
    "    # bm25 for whole document\n",
    "    corpus = []\n",
    "    prcessed_list = sorted(file_list)\n",
    "    for file in prcessed_list:\n",
    "        corpus.append(processed_file_dict[file]['processed_document'])\n",
    "    tokenized_corpus = [word_tokenizer.tokenize(doc) for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 332.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top K: 4\n",
      "Precision: 0.2760416666666667\n",
      "Recall: 0.2523809523809524\n",
      "F1: 0.26368159203980096\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_topk = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "\n",
    "for topk in [4]:\n",
    "    n_candidates = topk\n",
    "    candidate_dicts = {}\n",
    "\n",
    "    test_df = load_data(f'dataset/{split}.json')\n",
    "\n",
    "    for file in tqdm(test_df['source']):\n",
    "        query = get_query(file)\n",
    "        tokenized_query = word_tokenizer.tokenize(query)\n",
    "        results = bm25.get_scores(tokenized_query)\n",
    "        max_ids = np.argsort(results)[-n_candidates:]\n",
    "        document_candidates = [file_list[idx] for idx in max_ids]\n",
    "        candidate_dicts[file] = list(set(document_candidates))\n",
    "\n",
    "\n",
    "    test_df['candidates'] = test_df['source'].apply(lambda x: candidate_dicts[x])\n",
    "    test_df['query'] = test_df['source'].apply(lambda x: get_query(x))\n",
    "\n",
    "    # calculate accuracy metrics for BM25 + TF-IDF\n",
    "    correct = 0\n",
    "    n_retrived = 0\n",
    "    n_relevant = 0\n",
    "\n",
    "    coverages = []\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        source = row['source']\n",
    "        target = row['target']\n",
    "        preds = row['candidates']\n",
    "        coverages.append(len(preds))\n",
    "        n_retrived += len(preds)\n",
    "        n_relevant += len(target)\n",
    "        for prediction in preds:\n",
    "            if prediction in target:\n",
    "                correct += 1\n",
    "\n",
    "    precision = correct / n_retrived\n",
    "    recall = correct / n_relevant\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_topk = topk\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "\n",
    "print(f\"Top K: {best_topk}\")\n",
    "print(f\"Precision: {best_precision}\")\n",
    "print(f\"Recall: {best_recall}\")\n",
    "print(f\"F1: {best_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if split == 'submission':\n",
    "    n_candidates = best_topk\n",
    "    with open(f\"dataset/c2024/test_no_labels.json\", 'r') as fp:\n",
    "        test_keys = json.load(fp)\n",
    "    with open(f\"submissions/captainBM25.txt\", 'w') as fp:\n",
    "        for key in test_keys:\n",
    "            query = get_query(file)\n",
    "            tokenized_query = word_tokenizer.tokenize(query)\n",
    "            results = bm25.get_scores(tokenized_query)\n",
    "            max_ids = np.argsort(results)[-n_candidates:]\n",
    "            document_candidates = [file_list[idx] for idx in max_ids]\n",
    "            document_candidates = list(set(document_candidates))\n",
    "            for candidate in document_candidates:\n",
    "                fp.write(f\"{key.split('.')[0]} {candidate.split('.')[0]} captainBM25\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Top K: 4\n",
    "Precision: 0.16379310344827586\n",
    "Recall: 0.25150421179302046\n",
    "F1: 0.19838633127669672\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
